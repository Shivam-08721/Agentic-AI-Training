{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Python Asyncio: Building Efficient LLM Applications\n",
    "\n",
    "This notebook introduces asynchronous programming in Python using the `asyncio` library. In Day2, we're focusing on production-ready AI systems, and async programming is crucial for building efficient applications that can handle multiple LLM API calls concurrently.\n",
    "\n",
    "## Why Asyncio Matters for LLM Applications\n",
    "\n",
    "When working with LLM APIs:\n",
    "- **API calls are slow** (typically 1-10 seconds per request)\n",
    "- **You often need multiple calls** (different models, retries, parallel processing)\n",
    "- **Synchronous code wastes time** waiting for responses\n",
    "- **Asyncio enables concurrent requests**, dramatically improving performance\n",
    "\n",
    "## Preamble: Traditional Python vs. Asynchronous Python\n",
    "\n",
    "### Traditional (Synchronous) Python\n",
    "\n",
    "By default, Python executes code **synchronously** - operations happen one after another, in sequence. When Python encounters an operation that takes time (like network requests, file I/O, or database queries), it **blocks** and waits for that operation to complete before moving on.\n",
    "\n",
    "**Analogy**: Think of traditional Python like a chef who can only do one thing at a time. If the chef needs to boil water (which takes several minutes), they stand and watch the pot the entire time, unable to do any other cooking tasks until the water boils.\n",
    "\n",
    "### Asynchronous Python\n",
    "\n",
    "With `asyncio`, Python can execute code **asynchronously** - when an operation would normally block, Python can pause that operation, switch to another task, and then resume the first operation when it's ready.\n",
    "\n",
    "**Analogy**: Now imagine a chef who puts the water on to boil, and while waiting for it to boil, chops vegetables, marinates meat, and prepares sauces. The chef periodically checks if the water is boiling yet, but doesn't waste time just watching it. This is much more efficient!\n",
    "\n",
    "Let's see a simple example comparing these approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting breakfast...\n",
      "Brewing coffee...\n",
      "Coffee ready!\n",
      "Toasting bread...\n",
      "Toast ready!\n",
      "Frying eggs...\n",
      "Eggs ready!\n",
      "Breakfast prepared in 9.02 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Traditional synchronous approach\n",
    "def make_breakfast_sync():\n",
    "    print(\"Starting breakfast...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Brewing coffee...\")\n",
    "    time.sleep(3)  # Coffee takes 3 seconds to brew\n",
    "    print(\"Coffee ready!\")\n",
    "    \n",
    "    print(\"Toasting bread...\")\n",
    "    time.sleep(2)  # Toast takes 2 seconds\n",
    "    print(\"Toast ready!\")\n",
    "    \n",
    "    print(\"Frying eggs...\")\n",
    "    time.sleep(4)  # Eggs take 4 seconds\n",
    "    print(\"Eggs ready!\")\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Breakfast prepared in {end - start:.2f} seconds\")\n",
    "\n",
    "# Run the synchronous function\n",
    "make_breakfast_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the synchronous approach above, the total time is the sum of all individual tasks (3 + 2 + 4 = 9 seconds). This is because we can only do one thing at a time.\n",
    "\n",
    "Now let's see how this would work with `asyncio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting breakfast...\n",
      "Brewing coffee...\n",
      "Toasting bread...\n",
      "Frying eggs...\n",
      "Toast ready!\n",
      "Coffee ready!\n",
      "Eggs ready!\n",
      "Breakfast prepared in 4.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Asynchronous approach\n",
    "async def make_breakfast_async():\n",
    "    print(\"Starting breakfast...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Start all tasks concurrently\n",
    "    coffee_task = asyncio.create_task(brew_coffee())\n",
    "    toast_task = asyncio.create_task(make_toast())\n",
    "    eggs_task = asyncio.create_task(fry_eggs())\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    await coffee_task\n",
    "    await toast_task\n",
    "    await eggs_task\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Breakfast prepared in {end - start:.2f} seconds\")\n",
    "\n",
    "async def brew_coffee():\n",
    "    print(\"Brewing coffee...\")\n",
    "    await asyncio.sleep(3)  # Simulate brewing time\n",
    "    print(\"Coffee ready!\")\n",
    "    return \"coffee\"\n",
    "\n",
    "async def make_toast():\n",
    "    print(\"Toasting bread...\")\n",
    "    await asyncio.sleep(2)  # Simulate toasting time\n",
    "    print(\"Toast ready!\")\n",
    "    return \"toast\"\n",
    "\n",
    "async def fry_eggs():\n",
    "    print(\"Frying eggs...\")\n",
    "    await asyncio.sleep(4)  # Simulate frying time\n",
    "    print(\"Eggs ready!\")\n",
    "    return \"eggs\"\n",
    "\n",
    "# Run the asynchronous function\n",
    "# await asyncio.run(make_breakfast_async()) # works with .py files\n",
    "await make_breakfast_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the asynchronous approach, the total time is approximately 4 seconds (the longest individual task), not 9 seconds. This is because we're doing all three tasks concurrently, not one after another.\n",
    "\n",
    "Now let's dive into the core concepts of `asyncio` one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Event Loop & Concurrency Model\n",
    "\n",
    "The **event loop** is the core of every asyncio application. It's responsible for executing asynchronous tasks, handling I/O operations, and running callbacks.\n",
    "\n",
    "**Analogy**: Think of the event loop like a task manager who has a clipboard with a to-do list. The manager continuously cycles through the list:\n",
    "1. Checks each task to see if it's ready to make progress\n",
    "2. Gives attention to tasks that are ready to run\n",
    "3. When a task needs to wait (like for I/O), marks it as \"waiting\" and moves on to other tasks\n",
    "4. When a waiting task becomes ready, marks it as \"ready\" for the next cycle\n",
    "\n",
    "Let's see what happens when we define a coroutine but forget to run it through the event loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object say_hello at 0x000001F2F79B09C0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WRONG WAY - Defining a coroutine without running it\n",
    "async def say_hello():\n",
    "    print(\"Hello, World!\")\n",
    "    \n",
    "# This doesn't print anything - it just creates a coroutine object\n",
    "say_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that nothing actually happened! When you call a coroutine function directly, Python just creates a coroutine object but doesn't execute it. This is a common source of confusion for beginners.\n",
    "\n",
    "Now let's run it properly through the event loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# RIGHT WAY - Using asyncio.run() to run the coroutine\n",
    "#await asyncio.run(say_hello())\n",
    "await say_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it works! `asyncio.run()` creates an event loop, runs the coroutine until it completes, and then closes the loop.\n",
    "\n",
    "Let's see a slightly more complex example with multiple coroutines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 13:10:48\n",
      "Hello\n",
      "World\n",
      "Finished at 13:10:51\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, message):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(message)\n",
    "\n",
    "async def main():\n",
    "    print(f\"Started at {time.strftime('%X')}\")\n",
    "    \n",
    "    # These will run sequentially\n",
    "    await say_after(1, \"Hello\")\n",
    "    await say_after(2, \"World\")\n",
    "    \n",
    "    print(f\"Finished at {time.strftime('%X')}\")\n",
    "\n",
    "# Run the main coroutine\n",
    "# await asyncio.run(main())\n",
    "await main()\n",
    "# WRONG WAY - Using asyncio.run() inside an already running event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see two coroutines running sequentially (one after the other). The total time is the sum of the delays (about 3 seconds). This happens because we're awaiting each coroutine one at a time.\n",
    "\n",
    "Later, we'll see how to run coroutines concurrently for better efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coroutines & async/await Syntax\n",
    "\n",
    "**Coroutines** are special functions defined with `async def` that can pause their execution at `await` points. When a coroutine awaits something, it temporarily gives up control to the event loop, which can then run other coroutines.\n",
    "\n",
    "**Analogy**: Think of coroutines like restaurant workers. When a worker needs to wait for something (like an order to be ready from the kitchen), they don't just stand there blocking the whole restaurant. Instead, they say \"I'll wait for this\" (await) and go help other customers until the order is ready.\n",
    "\n",
    "Let's see what happens when we try to use a coroutine incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: <coroutine object get_data at 0x000001F2F79B0EC0>\n"
     ]
    }
   ],
   "source": [
    "# WRONG WAY - Trying to directly use a coroutine without await\n",
    "async def get_data():\n",
    "    print(\"Fetching data...\")\n",
    "    await asyncio.sleep(1)  # Simulate network delay\n",
    "    print(\"Data retrieved!\")\n",
    "    return {\"status\": \"success\", \"data\": [1, 2, 3]}\n",
    "\n",
    "# This just creates a coroutine object without running it\n",
    "result = get_data()\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we didn't get the actual data - we just got a coroutine object. This is because we didn't await the coroutine or run it through the event loop.\n",
    "\n",
    "Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Data retrieved!\n",
      "Result: {'status': 'success', 'data': [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "# RIGHT WAY - Using await to get the result of a coroutine\n",
    "async def main():\n",
    "    result = await get_data()\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Run the main coroutine\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the actual data! The `await` keyword tells Python to pause the current coroutine until `get_data()` completes, then resume with its result.\n",
    "\n",
    "Key things to remember about coroutines:\n",
    "- They must be defined with `async def`\n",
    "- They can contain `await` expressions\n",
    "- They can only be called from other coroutines (with `await`)\n",
    "- To call them from synchronous code, use `asyncio.run()`\n",
    "\n",
    "Let's see an example with multiple await points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetching raw data...\n",
      "Raw data: [1, 2, 3, 4, 5]\n",
      "Step 2: Processing data...\n",
      "Processed data: [2, 4, 6, 8, 10]\n",
      "Step 3: Saving results...\n",
      "Data saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def process_data():\n",
    "    print(\"Step 1: Fetching raw data...\")\n",
    "    await asyncio.sleep(1)  # Simulate network delay\n",
    "    raw_data = [1, 2, 3, 4, 5]\n",
    "    print(f\"Raw data: {raw_data}\")\n",
    "    \n",
    "    print(\"Step 2: Processing data...\")\n",
    "    await asyncio.sleep(0.5)  # Simulate processing time\n",
    "    processed_data = [x * 2 for x in raw_data]\n",
    "    print(f\"Processed data: {processed_data}\")\n",
    "    \n",
    "    print(\"Step 3: Saving results...\")\n",
    "    await asyncio.sleep(0.8)  # Simulate database delay\n",
    "    print(\"Data saved successfully!\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# await asyncio.run(process_data())\n",
    "await process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the coroutine has three await points, each simulating a different operation. At each `await`, the coroutine pauses and the event loop could potentially run other coroutines (though we only have one in this example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tasks & Futures\n",
    "\n",
    "**Tasks** are a way to schedule coroutines to run concurrently on the event loop. A Task wraps a coroutine and manages its execution, allowing you to check its status, cancel it, or get its result.\n",
    "\n",
    "**Futures** are a lower-level awaitable object representing the result of an operation that hasn't yet completed. Think of a Future as a \"promise\" that will eventually have a result.\n",
    "\n",
    "**Analogy**: If a coroutine is like a recipe for cooking a dish, a Task is like giving that recipe to a chef and saying \"make this dish.\" The Task represents the ongoing work, and you can check if it's done, cancel it, or wait for the finished dish.\n",
    "\n",
    "Let's see what happens when we create a Task but forget to await it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main function finished\n",
      "Calculating sum...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum calculated: 15\n"
     ]
    }
   ],
   "source": [
    "# WRONG WAY - Creating a task but not awaiting it\n",
    "async def calculate_sum(numbers):\n",
    "    print(\"Calculating sum...\")\n",
    "    await asyncio.sleep(1)  # Simulate computation time\n",
    "    result = sum(numbers)\n",
    "    print(f\"Sum calculated: {result}\")\n",
    "    return result\n",
    "\n",
    "async def main():\n",
    "    # Create a task\n",
    "    task = asyncio.create_task(calculate_sum([1, 2, 3, 4, 5]))\n",
    "    \n",
    "    # Oops! We forgot to await the task\n",
    "    print(\"Main function finished\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the main function finished immediately, but the sum calculation may or may not complete (depending on whether the event loop was closed before it finished). If we don't await the task, we can't get its result or ensure it completes.\n",
    "\n",
    "Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main function continues immediately while the task runs\n",
      "Doing other work...\n",
      "Calculating sum...\n",
      "Sum calculated: 15\n",
      "Got task result: 15\n",
      "Main function finished\n"
     ]
    }
   ],
   "source": [
    "# RIGHT WAY - Creating and awaiting a task\n",
    "async def main():\n",
    "    # Create a task\n",
    "    task = asyncio.create_task(calculate_sum([1, 2, 3, 4, 5]))\n",
    "    \n",
    "    print(\"Main function continues immediately while the task runs\")\n",
    "    print(\"Doing other work...\")\n",
    "    await asyncio.sleep(0.5)  # Simulate other work\n",
    "    \n",
    "    # Now await the task result\n",
    "    result = await task\n",
    "    print(f\"Got task result: {result}\")\n",
    "    print(\"Main function finished\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we properly await the task and get its result. Notice how the main function continues running immediately after creating the task (before the sum is calculated), demonstrating concurrency.\n",
    "\n",
    "We can also check a task's status and handle multiple tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task A done? False\n",
      "Task B done? False\n",
      "Task A starting...\n",
      "Task B starting...\n",
      "Task B completed after 1 seconds\n",
      "Task A completed after 2 seconds\n",
      "Task A done? True\n",
      "Task B done? True\n",
      "Results: Result from A, Result from B\n"
     ]
    }
   ],
   "source": [
    "async def delayed_task(delay, name):\n",
    "    print(f\"Task {name} starting...\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"Task {name} completed after {delay} seconds\")\n",
    "    return f\"Result from {name}\"\n",
    "\n",
    "async def main():\n",
    "    # Create multiple tasks\n",
    "    task1 = asyncio.create_task(delayed_task(2, \"A\"))\n",
    "    task2 = asyncio.create_task(delayed_task(1, \"B\"))\n",
    "    \n",
    "    # Check task status\n",
    "    print(f\"Task A done? {task1.done()}\")\n",
    "    print(f\"Task B done? {task2.done()}\")\n",
    "    \n",
    "    # Wait for tasks to complete\n",
    "    result1 = await task1\n",
    "    result2 = await task2\n",
    "    \n",
    "    # Check task status again\n",
    "    print(f\"Task A done? {task1.done()}\")\n",
    "    print(f\"Task B done? {task2.done()}\")\n",
    "    \n",
    "    print(f\"Results: {result1}, {result2}\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how both tasks run concurrently, and task B (with a shorter delay) completes before task A, even though we created task A first. We can check a task's status using `task.done()` and get its result using `await task`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scheduling & Aggregation: create_task, gather, wait\n",
    "\n",
    "Asyncio provides several ways to schedule and manage multiple coroutines:\n",
    "\n",
    "1. **create_task**: Schedules a coroutine to run as a Task on the event loop\n",
    "2. **gather**: Runs multiple awaitables concurrently and returns all their results\n",
    "3. **wait**: Waits for multiple awaitables with fine-grained control over waiting behavior\n",
    "\n",
    "**Analogy**: Think of `create_task` like assigning jobs to different workers, `gather` like waiting for all workers to finish and collecting their results, and `wait` like having more selective policies about which workers you want to wait for (first to finish, all of them, etc.).\n",
    "\n",
    "Let's first see what happens when we don't use these functions and try to run tasks sequentially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for item 1...\n",
      "Fetching data for item 2...\n",
      "Fetching data for item 3...\n",
      "Results: ['Data for item 1', 'Data for item 2', 'Data for item 3']\n",
      "Time taken: 3.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# WRONG WAY - Running coroutines sequentially when they could be concurrent\n",
    "async def fetch_data(item_id):\n",
    "    print(f\"Fetching data for item {item_id}...\")\n",
    "    await asyncio.sleep(1)  # Simulate API request delay\n",
    "    return f\"Data for item {item_id}\"\n",
    "\n",
    "async def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Sequential execution\n",
    "    result1 = await fetch_data(1)\n",
    "    result2 = await fetch_data(2)\n",
    "    result3 = await fetch_data(3)\n",
    "    \n",
    "    results = [result1, result2, result3]\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it takes around 3 seconds because we're executing the coroutines one after another. Let's fix this using `create_task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for item 1...\n",
      "Fetching data for item 2...\n",
      "Fetching data for item 3...\n",
      "Results: ['Data for item 1', 'Data for item 2', 'Data for item 3']\n",
      "Time taken: 1.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# BETTER WAY 1 - Using create_task for concurrency\n",
    "async def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create tasks to run concurrently\n",
    "    task1 = asyncio.create_task(fetch_data(1))\n",
    "    task2 = asyncio.create_task(fetch_data(2))\n",
    "    task3 = asyncio.create_task(fetch_data(3))\n",
    "    \n",
    "    # Await all tasks to complete\n",
    "    result1 = await task1\n",
    "    result2 = await task2\n",
    "    result3 = await task3\n",
    "    \n",
    "    results = [result1, result2, result3]\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better! Now it takes only around 1 second because all tasks run concurrently. But we can make the code more concise using `gather`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for item 1...\n",
      "Fetching data for item 2...\n",
      "Fetching data for item 3...\n",
      "Results: ['Data for item 1', 'Data for item 2', 'Data for item 3']\n",
      "Time taken: 1.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# BEST WAY - Using gather for concurrency\n",
    "async def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use gather to run all coroutines concurrently\n",
    "    results = await asyncio.gather(\n",
    "        fetch_data(1),\n",
    "        fetch_data(2),\n",
    "        fetch_data(3)\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gather` is very convenient because it runs all the coroutines concurrently and returns their results in the same order. It's perfect when you need to run multiple operations at once and get all their results.\n",
    "\n",
    "Now let's try `wait`, which gives you more control over how you wait for tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waiting for the first task to complete...\n",
      "Fetching item 1 (delay: 1s)...\n",
      "Fetching item 2 (delay: 2s)...\n",
      "Fetching item 3 (delay: 3s)...\n",
      "Item 1 fetched!\n",
      "\n",
      "1 tasks completed, 2 tasks still pending.\n",
      "Processing completed tasks:\n",
      "Result: Data for item 1\n",
      "\n",
      "Waiting for remaining tasks with a 1.5s timeout...\n",
      "Item 2 fetched!\n",
      "\n",
      "1 more tasks completed, 1 tasks still pending.\n",
      "Cancelling remaining tasks...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# Using wait with different options\n",
    "async def fetch_with_variable_delay(item_id, delay):\n",
    "    print(f\"Fetching item {item_id} (delay: {delay}s)...\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"Item {item_id} fetched!\")\n",
    "    return f\"Data for item {item_id}\"\n",
    "\n",
    "async def main():\n",
    "    # Create tasks with different delays\n",
    "    task1 = asyncio.create_task(fetch_with_variable_delay(1, 1))\n",
    "    task2 = asyncio.create_task(fetch_with_variable_delay(2, 2))\n",
    "    task3 = asyncio.create_task(fetch_with_variable_delay(3, 3))\n",
    "    \n",
    "    # Wait for the first task to complete\n",
    "    print(\"\\nWaiting for the first task to complete...\")\n",
    "    done, pending = await asyncio.wait(\n",
    "        [task1, task2, task3],\n",
    "        return_when=asyncio.FIRST_COMPLETED\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{len(done)} tasks completed, {len(pending)} tasks still pending.\")\n",
    "    \n",
    "    # Process the completed task\n",
    "    print(\"Processing completed tasks:\")\n",
    "    for done_task in done:\n",
    "        result = done_task.result()\n",
    "        print(f\"Result: {result}\")\n",
    "    \n",
    "    # Wait for remaining tasks with a timeout\n",
    "    print(\"\\nWaiting for remaining tasks with a 1.5s timeout...\")\n",
    "    done, pending = await asyncio.wait(pending, timeout=1.5)\n",
    "    \n",
    "    print(f\"\\n{len(done)} more tasks completed, {len(pending)} tasks still pending.\")\n",
    "    \n",
    "    # Cancel remaining tasks\n",
    "    print(\"Cancelling remaining tasks...\")\n",
    "    for task in pending:\n",
    "        task.cancel()\n",
    "    \n",
    "    print(\"All done!\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`asyncio.wait()` is more flexible than `gather` because it allows you to:\n",
    "- Wait for just the first task to complete (`FIRST_COMPLETED`)\n",
    "- Wait for a specific number of tasks to complete (`FIRST_EXCEPTION`)\n",
    "- Wait for all tasks to complete (`ALL_COMPLETED`, which is the default)\n",
    "- Set a timeout for waiting\n",
    "- Get separate sets of done and pending tasks\n",
    "\n",
    "This is useful for more complex scenarios, like processing results as soon as they're available, or implementing timeouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Example: Async LLM API Calls\n",
    "\n",
    "Now let's see how asyncio can dramatically improve performance when working with LLM APIs. This example simulates making multiple LLM API calls, which is a common pattern in production AI applications.\n",
    "\n",
    "### The Problem: Sequential API Calls Are Slow\n",
    "\n",
    "Imagine you need to:\n",
    "1. Query multiple models for comparison\n",
    "2. Process multiple documents through an LLM\n",
    "3. Implement retry logic for failed requests\n",
    "4. Make follow-up calls based on initial responses\n",
    "\n",
    "Without asyncio, these operations would happen one after another, wasting valuable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sequential Processing ===\n",
      "[gpt-4] Sending request: 'What is the capital of France?...'\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Sending request: 'Explain quantum computing in s...'\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Sending request: 'Write a haiku about programmin...'\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Sending request: 'What are the benefits of async...'\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Sending request: 'How do neural networks work?...'\n",
      "[gpt-4] Received response\n",
      "Sequential processing took: 10.04 seconds\n",
      "\n",
      "=== Concurrent Processing ===\n",
      "[gpt-4] Sending request: 'What is the capital of France?...'\n",
      "[gpt-4] Sending request: 'Explain quantum computing in s...'\n",
      "[gpt-4] Sending request: 'Write a haiku about programmin...'\n",
      "[gpt-4] Sending request: 'What are the benefits of async...'\n",
      "[gpt-4] Sending request: 'How do neural networks work?...'\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Received response\n",
      "[gpt-4] Received response\n",
      "Concurrent processing took: 2.01 seconds\n",
      "\n",
      "Speedup: 5.0x faster with concurrent processing!\n"
     ]
    }
   ],
   "source": [
    "# Simulating LLM API calls (we'll use delays to simulate API latency)\n",
    "\n",
    "async def simulate_llm_api_call(prompt, model_name, delay=2):\n",
    "    \"\"\"Simulates an LLM API call with network delay\"\"\"\n",
    "    print(f\"[{model_name}] Sending request: '{prompt[:30]}...'\")\n",
    "    await asyncio.sleep(delay)  # Simulate API latency\n",
    "    response = f\"Response from {model_name}: This is a simulated response to '{prompt}'\"\n",
    "    print(f\"[{model_name}] Received response\")\n",
    "    return response\n",
    "\n",
    "# SLOW WAY - Sequential API calls\n",
    "async def process_prompts_sequential(prompts, model=\"gpt-4\"):\n",
    "    print(\"\\n=== Sequential Processing ===\")\n",
    "    start_time = time.time()\n",
    "    responses = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        response = await simulate_llm_api_call(prompt, model)\n",
    "        responses.append(response)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Sequential processing took: {end_time - start_time:.2f} seconds\")\n",
    "    return responses\n",
    "\n",
    "# FAST WAY - Concurrent API calls\n",
    "async def process_prompts_concurrent(prompts, model=\"gpt-4\"):\n",
    "    print(\"\\n=== Concurrent Processing ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create tasks for all prompts\n",
    "    tasks = [simulate_llm_api_call(prompt, model) for prompt in prompts]\n",
    "    \n",
    "    # Run all tasks concurrently\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Concurrent processing took: {end_time - start_time:.2f} seconds\")\n",
    "    return responses\n",
    "\n",
    "# Test with multiple prompts\n",
    "async def main():\n",
    "    prompts = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Explain quantum computing in simple terms\",\n",
    "        \"Write a haiku about programming\",\n",
    "        \"What are the benefits of async programming?\",\n",
    "        \"How do neural networks work?\"\n",
    "    ]\n",
    "    \n",
    "    # Run sequential version\n",
    "    sequential_results = await process_prompts_sequential(prompts)\n",
    "    \n",
    "    # Run concurrent version\n",
    "    concurrent_results = await process_prompts_concurrent(prompts)\n",
    "    \n",
    "    print(f\"\\nSpeedup: {5*2/2:.1f}x faster with concurrent processing!\")\n",
    "\n",
    "# await asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Pattern: Multi-Model Comparison\n",
    "\n",
    "A common pattern in production is querying multiple models simultaneously to compare their responses or implement fallback strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying 4 models with prompt: 'What are the key principles of software engineerin...'\n",
      "[gpt-4] Sending request: 'What are the key principles of...'\n",
      "[claude-3] Sending request: 'What are the key principles of...'\n",
      "[gemini-pro] Sending request: 'What are the key principles of...'\n",
      "[llama-70b] Sending request: 'What are the key principles of...'\n",
      "[gpt-4] Received response\n",
      "[claude-3] Received response\n",
      "[gemini-pro] Received response\n",
      "[llama-70b] Received response\n",
      "All models responded in: 2.50 seconds\n",
      "\n",
      "Model comparison results:\n",
      "- gpt-4: Response from gpt-4: This is a simulated response ...\n",
      "- claude-3: Response from claude-3: This is a simulated respon...\n",
      "- gemini-pro: Response from gemini-pro: This is a simulated resp...\n",
      "- llama-70b: Response from llama-70b: This is a simulated respo...\n",
      "\n",
      "Trying primary model: expensive-slow-model\n",
      "[expensive-slow-model] Sending request: 'Explain async programming...'\n",
      "Primary model timed out after 3s, trying fallbacks...\n",
      "[fast-model-1] Sending request: 'Explain async programming...'\n",
      "[fast-model-2] Sending request: 'Explain async programming...'\n",
      "[fast-model-3] Sending request: 'Explain async programming...'\n",
      "[fast-model-1] Received response\n",
      "[fast-model-2] Received response\n",
      "[fast-model-3] Received response\n",
      "\n",
      "Fallback result from fast-model-2\n"
     ]
    }
   ],
   "source": [
    "# Multi-model comparison pattern\n",
    "async def query_multiple_models(prompt, models):\n",
    "    \"\"\"Query multiple models concurrently and return all responses\"\"\"\n",
    "    print(f\"\\nQuerying {len(models)} models with prompt: '{prompt[:50]}...'\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create tasks for each model with different simulated latencies\n",
    "    tasks = []\n",
    "    for i, model in enumerate(models):\n",
    "        # Simulate different response times for different models\n",
    "        delay = 1 + i * 0.5  # Models have different latencies\n",
    "        # task = simulate_llm_api_call(prompt, model, delay) \n",
    "        task = asyncio.create_task(simulate_llm_api_call(prompt, model, delay))\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Run all model queries concurrently\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"All models responded in: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Return model-response pairs\n",
    "    return dict(zip(models, responses))\n",
    "\n",
    "# Fallback pattern with timeout\n",
    "async def query_with_fallback(prompt, primary_model, fallback_models, timeout=3):\n",
    "    \"\"\"Try primary model first, fallback to others if it times out\"\"\"\n",
    "    print(f\"\\nTrying primary model: {primary_model}\")\n",
    "    \n",
    "    try:\n",
    "        # Try primary model with timeout\n",
    "        response = await asyncio.wait_for(\n",
    "            simulate_llm_api_call(prompt, primary_model, delay=4),  # Simulate slow primary\n",
    "            timeout=timeout\n",
    "        )\n",
    "        print(f\"Primary model succeeded!\")\n",
    "        return {\"model\": primary_model, \"response\": response}\n",
    "    \n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Primary model timed out after {timeout}s, trying fallbacks...\")\n",
    "        \n",
    "        # Try fallback models concurrently\n",
    "        # tasks = [simulate_llm_api_call(prompt, model, delay=1) for model in fallback_models]\n",
    "        tasks = [asyncio.create_task(simulate_llm_api_call(prompt, model, delay=1)) for model in fallback_models]\n",
    "        \n",
    "        # Get the first successful response\n",
    "        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "        \n",
    "        # Cancel remaining tasks\n",
    "        for task in pending:\n",
    "            task.cancel()\n",
    "        \n",
    "        # Return the first successful response\n",
    "        first_response = list(done)[0].result()\n",
    "        model_index = tasks.index(list(done)[0])\n",
    "        return {\"model\": fallback_models[model_index], \"response\": first_response}\n",
    "\n",
    "# Test the patterns\n",
    "async def test_advanced_patterns():\n",
    "    # Test multi-model comparison\n",
    "    models = [\"gpt-4\", \"claude-3\", \"gemini-pro\", \"llama-70b\"]\n",
    "    prompt = \"What are the key principles of software engineering?\"\n",
    "    \n",
    "    results = await query_multiple_models(prompt, models)\n",
    "    print(\"\\nModel comparison results:\")\n",
    "    for model, response in results.items():\n",
    "        print(f\"- {model}: {response[:50]}...\")\n",
    "    \n",
    "    # Test fallback pattern\n",
    "    fallback_result = await query_with_fallback(\n",
    "        \"Explain async programming\",\n",
    "        primary_model=\"expensive-slow-model\",\n",
    "        fallback_models=[\"fast-model-1\", \"fast-model-2\", \"fast-model-3\"]\n",
    "    )\n",
    "    print(f\"\\nFallback result from {fallback_result['model']}\")\n",
    "\n",
    "# await asyncio.run(test_advanced_patterns())\n",
    "await test_advanced_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways for LLM Applications\n",
    "\n",
    "1. **Always use async for LLM API calls** - The performance gains are significant\n",
    "2. **Use `gather()` for batch processing** - Process multiple prompts or documents concurrently\n",
    "3. **Implement timeouts** - Protect against slow or hanging API calls\n",
    "4. **Consider fallback strategies** - Use multiple models for reliability\n",
    "5. **Handle rate limits gracefully** - Async makes it easier to implement rate limiting\n",
    "\n",
    "### Coming Next in Day2\n",
    "\n",
    "Now that you understand asyncio fundamentals, you'll see how to apply these concepts in:\n",
    "- **Model Selection & Parameter Tuning**: Compare models concurrently\n",
    "- **Token Management**: Process large documents efficiently\n",
    "- **Error Handling**: Implement robust retry logic with async patterns\n",
    "\n",
    "Remember: In production AI applications, the difference between sequential and concurrent processing can be the difference between a 10-second response time and a 2-second response time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
