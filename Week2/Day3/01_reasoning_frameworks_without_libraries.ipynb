{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning Frameworks Without Libraries\n",
    "\n",
    "This notebook demonstrates how to implement advanced reasoning frameworks for LLM agents without relying on specialized libraries. We'll explore:\n",
    "\n",
    "- ReAct pattern implementation from scratch\n",
    "- Building a planning-execution loop\n",
    "- Reflection and self-correction mechanisms\n",
    "- Implementing chain-of-thought in raw prompts\n",
    "\n",
    "By building these reasoning patterns from the ground up, you'll gain a deeper understanding of how they work and how to customize them for your specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's set up our environment and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: tenacity in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (9.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv requests tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully!\n",
      "API key: sk-...843\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import uuid\n",
    "from typing import Dict, List, Any, Optional, Union, Tuple, Callable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directory to path to import utility functions\n",
    "sys.path.append('../../Week1/Day2')\n",
    "\n",
    "# Import our API utilities\n",
    "from api_utils import (\n",
    "    call_openrouter,\n",
    "    extract_text_response,\n",
    "    extract_function_call,\n",
    "    get_available_models\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✅ API key loaded successfully!\")\n",
    "    # Show first and last three characters for verification\n",
    "    masked_key = f\"{api_key[:3]}...{api_key[-3:]}\" if len(api_key) > 6 else \"[key too short]\"\n",
    "    print(f\"API key: {masked_key}\")\n",
    "else:\n",
    "    print(\"❌ API key not found! Make sure you've created a .env file with your OPENROUTER_API_KEY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chain of Thought (CoT) Prompting\n",
    "\n",
    "Chain of Thought (CoT) is a prompting technique that encourages the model to show its reasoning process step by step. This typically improves performance on complex reasoning tasks by breaking them down into manageable steps.\n",
    "\n",
    "Let's implement a simple CoT approach without any libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A merchant has 50 fruits in total, consisting of apples, oranges, and bananas. He has twice as many apples as oranges, and 5 more bananas than oranges. How many of each fruit does he have?\n",
      "\n",
      "Chain of Thought Response:\n",
      "Let me think through this step by step:\n",
      "\n",
      "1. **Understand what the question is asking**: We need to find out how many apples, oranges, and bananas the merchant has, given the total number of fruits and the relationships between the quantities of each type of fruit.\n",
      "\n",
      "2. **Identify the key information and constraints**:\n",
      "   - Total fruits = 50\n",
      "   - Let the number of oranges be \\( x \\).\n",
      "   - The number of apples is twice the number of oranges: \\( 2x \\).\n",
      "   - The number of bananas is 5 more than the number of oranges: \\( x + 5 \\).\n",
      "\n",
      "3. **Consider different approaches to solve the problem**: We can set up an equation based on the total number of fruits and the relationships given.\n",
      "\n",
      "4. **Walk through the solution step by step**:\n",
      "   - We know the total number of fruits:\n",
      "     \\[\n",
      "     \\text{Total fruits} = \\text{Number of apples} + \\text{Number of oranges} + \\text{Number of bananas}\n",
      "     \\]\n",
      "   - Substituting the expressions we have:\n",
      "     \\[\n",
      "     50 = 2x + x + (x + 5)\n",
      "     \\]\n",
      "   - Simplifying the equation:\n",
      "     \\[\n",
      "     50 = 2x + x + x + 5\n",
      "     \\]\n",
      "     \\[\n",
      "     50 = 4x + 5\n",
      "     \\]\n",
      "   - Now, isolate \\( x \\):\n",
      "     \\[\n",
      "     50 - 5 = 4x\n",
      "     \\]\n",
      "     \\[\n",
      "     45 = 4x\n",
      "     \\]\n",
      "     \\[\n",
      "     x = \\frac{45}{4} = 11.25\n",
      "     \\]\n",
      "   - Since \\( x \\) must be a whole number (you can't have a fraction of a fruit), let's recheck our equations. \n",
      "\n",
      "   - It seems I made a mistake in my setup. Let's redefine \\( x \\) correctly:\n",
      "     - Let \\( x \\) be the number of oranges.\n",
      "     - Then, the number of apples is \\( 2x \\).\n",
      "     - The number of bananas is \\( x + 5 \\).\n",
      "   - The correct equation should be:\n",
      "     \\[\n",
      "     50 = 2x + x + (x + 5)\n",
      "     \\]\n",
      "     \\[\n",
      "     50 = 4x + 5\n",
      "     \\]\n",
      "     \\[\n",
      "     50 - 5 = 4x\n",
      "     \\]\n",
      "     \\[\n",
      "     45 = 4x\n",
      "     \\]\n",
      "     \\[\n",
      "     x = 11.25\n",
      "     \\]\n",
      "   - I realize I need to check my setup again. Let's assume \\( x \\) is the number of oranges, then:\n",
      "     - Apples = \\( 2x \\)\n",
      "     - Bananas = \\( x + 5 \\)\n",
      "   - The equation should be:\n",
      "     \\[\n",
      "     50 = 2x + x + (x + 5)\n",
      "     \\]\n",
      "     \\[\n",
      "     50 = 4x + 5\n",
      "     \\]\n",
      "     \\[\n",
      "     45 = 4x\n",
      "     \\]\n",
      "     \\[\n",
      "     x = 11.25\n",
      "     \\]\n",
      "   - This is incorrect, as I need integers. Let's redefine:\n",
      "     - Let \\( y \\) be the number of oranges, then:\n",
      "     - Apples = \\( 2y \\)\n",
      "     - Bananas = \\( y + 5 \\)\n",
      "   - The equation:\n",
      "     \\[\n",
      "     50 = 2y + y + (y + 5)\n",
      "     \\]\n",
      "     \\[\n",
      "     50 = 4y + 5\n",
      "     \\]\n",
      "     \\[\n",
      "     45 = 4y\n",
      "     \\]\n",
      "     \\[\n",
      "     y = 11.25\n",
      "     \\]\n",
      "   - I realize I need to set up correctly:\n",
      "     - Let \\( y\n"
     ]
    }
   ],
   "source": [
    "def chain_of_thought(question: str, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> str:\n",
    "    \"\"\"Apply chain-of-thought prompting to encourage step-by-step reasoning.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        model: The LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        The model's response with reasoning steps\n",
    "    \"\"\"\n",
    "    # System prompt that encourages step-by-step reasoning\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert problem-solver who thinks through problems step by step.\n",
    "    When given a question, break down your thinking process into clear steps:\n",
    "    1. Understand what the question is asking\n",
    "    2. Identify the key information and constraints\n",
    "    3. Consider different approaches to solve the problem\n",
    "    4. Walk through the solution step by step\n",
    "    5. Verify the answer to ensure it makes sense\n",
    "    \n",
    "    Structure your answers with clear reasoning steps, showing your full thought process.\n",
    "    Start with \"Let me think through this step by step:\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the API call\n",
    "    response = call_openrouter(\n",
    "        prompt=question,\n",
    "        model=model,\n",
    "        system_prompt=system_prompt,\n",
    "        temperature=0.3, # Lower temperature for more logical reasoning\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if response.get(\"success\", False):\n",
    "        return extract_text_response(response)\n",
    "    else:\n",
    "        return f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "\n",
    "# Test with a complex reasoning question\n",
    "cot_question = \"A merchant has 50 fruits in total, consisting of apples, oranges, and bananas. He has twice as many apples as oranges, and 5 more bananas than oranges. How many of each fruit does he have?\"\n",
    "\n",
    "print(f\"Question: {cot_question}\\n\")\n",
    "print(\"Chain of Thought Response:\")\n",
    "print(chain_of_thought(cot_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Chain of Thought with Few-Shot Examples\n",
    "\n",
    "We can further enhance CoT by providing few-shot examples in the prompt. This helps the model understand the expected reasoning pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A merchant has 50 fruits in total, consisting of apples, oranges, and bananas. He has twice as many apples as oranges, and 5 more bananas than oranges. How many of each fruit does he have?\n",
      "\n",
      "Few-Shot Chain of Thought Response:\n",
      "1. Let the number of oranges be \\( x \\).\n",
      "2. According to the problem, the number of apples is \\( 2x \\) (twice as many apples as oranges).\n",
      "3. The number of bananas is \\( x + 5 \\) (5 more bananas than oranges).\n",
      "4. The total number of fruits is given as 50. Therefore, we can set up the equation:\n",
      "   \\[\n",
      "   x + 2x + (x + 5) = 50\n",
      "   \\]\n",
      "5. Simplifying the equation:\n",
      "   \\[\n",
      "   4x + 5 = 50\n",
      "   \\]\n",
      "6. Subtracting 5 from both sides:\n",
      "   \\[\n",
      "   4x = 45\n",
      "   \\]\n",
      "7. Dividing both sides by 4:\n",
      "   \\[\n",
      "   x = 11.25\n",
      "   \\]\n",
      "   (This indicates that there is an issue since the number of fruits should be a whole number.)\n",
      "\n",
      "Let's re-evaluate the problem. \n",
      "\n",
      "1. Let the number of oranges be \\( x \\).\n",
      "2. The number of apples is \\( 2x \\).\n",
      "3. The number of bananas is \\( x + 5 \\).\n",
      "4. The total number of fruits is:\n",
      "   \\[\n",
      "   x + 2x + (x + 5) = 50\n",
      "   \\]\n",
      "5. This simplifies to:\n",
      "   \\[\n",
      "   4x + 5 = 50\n",
      "   \\]\n",
      "6. Solving for \\( x \\):\n",
      "   \\[\n",
      "   4x = 45 \\implies x = 11.25\n",
      "   \\]\n",
      "   \n",
      "Since \\( x \\) must be a whole number, let's check the relationships again:\n",
      "\n",
      "1. If we assume \\( x \\) is the number of oranges, let’s try substituting \\( x \\) with a whole number that fits the relationships.\n",
      "2. If we set \\( x = 10 \\) (a whole number):\n",
      "   - Then, the number of oranges = 10\n",
      "   - The number of apples = \\( 2 \\times 10 = 20 \\)\n",
      "   - The number of bananas = \\( 10 + 5 = 15 \\)\n",
      "3. Now, checking the total:\n",
      "   \\[\n",
      "   10 + 20 + 15 = 45 \\quad \\text{(not 50)}\n",
      "   \\]\n",
      "\n",
      "Let’s try \\( x = 12 \\):\n",
      "1. If \\( x = 12 \\):\n",
      "   - Oranges = 12\n",
      "   - Apples = \\( 2 \\times 12 = 24 \\)\n",
      "   - Bananas = \\( 12 + 5 = 17 \\)\n",
      "2. Total:\n",
      "   \\[\n",
      "   12 + 24 + 17 = 53 \\quad \\text{(not 50)}\n",
      "   \\]\n",
      "\n",
      "Let’s try \\( x = 8 \\):\n",
      "1. If \\( x = 8 \\):\n",
      "   - Oranges = 8\n",
      "   - Apples = \\( 2 \\times 8 = 16 \\)\n",
      "   - Bananas = \\( 8 + 5 = 13 \\)\n",
      "2. Total:\n",
      "   \\[\n",
      "   8 + 16 + 13 = 37 \\quad \\text{(not 50)}\n",
      "   \\]\n",
      "\n",
      "Let’s try \\( x = 7 \\):\n",
      "1. If \\( x = 7 \\):\n",
      "   - Oranges = 7\n",
      "   - Apples = \\( 2 \\times 7 = 14 \\)\n",
      "   - Bananas = \\( 7 + 5 = 12 \\)\n",
      "2. Total:\n",
      "   \\[\n",
      "   7 + 14 + 12 = 33 \\quad \\text{(not 50)}\n",
      "   \\]\n",
      "\n",
      "Let’s try \\( x = 6 \\):\n",
      "1. If \\( x = 6 \\):\n",
      "   - Oranges = 6\n",
      "   - Apples = \\( 2 \\times 6\n"
     ]
    }
   ],
   "source": [
    "def few_shot_cot(question: str, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> str:\n",
    "    \"\"\"Apply chain-of-thought prompting with few-shot examples.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        model: The LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        The model's response with reasoning steps\n",
    "    \"\"\"\n",
    "    # Create a prompt with few-shot examples\n",
    "    few_shot_prompt = \"\"\"\n",
    "    I'll solve each problem step by step.\n",
    "    \n",
    "    Problem: If John has 5 apples and eats 2, then buys 3 more, how many apples does he have?\n",
    "    Solution: Let me think through this step by step.\n",
    "    1. Initially, John has 5 apples.\n",
    "    2. He eats 2 apples, so he has 5 - 2 = 3 apples left.\n",
    "    3. Then he buys 3 more apples, so he has 3 + 3 = 6 apples total.\n",
    "    4. Therefore, John has 6 apples.\n",
    "    \n",
    "    Problem: A rectangle has a perimeter of 24 cm and a width of 4 cm. What is its area?\n",
    "    Solution: Let me think through this step by step.\n",
    "    1. The perimeter of a rectangle is 2 × (length + width).\n",
    "    2. Given that the perimeter is 24 cm and width is 4 cm.\n",
    "    3. 24 = 2 × (length + 4)\n",
    "    4. 12 = length + 4\n",
    "    5. length = 8 cm\n",
    "    6. The area of a rectangle is length × width = 8 cm × 4 cm = 32 cm²\n",
    "    7. Therefore, the area of the rectangle is 32 square centimeters.\n",
    "    \n",
    "    Problem: {question}\n",
    "    Solution: Let me think through this step by step.\n",
    "    \"\"\".format(question=question)\n",
    "    \n",
    "    # Make the API call\n",
    "    response = call_openrouter(\n",
    "        prompt=few_shot_prompt,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if response.get(\"success\", False):\n",
    "        return extract_text_response(response)\n",
    "    else:\n",
    "        return f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "\n",
    "# Test with the same question to compare results\n",
    "print(f\"Question: {cot_question}\\n\")\n",
    "print(\"Few-Shot Chain of Thought Response:\")\n",
    "print(few_shot_cot(cot_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Let's Compare Different Reasoning Approaches\n",
    "\n",
    "Let's compare regular prompting, chain of thought, and few-shot CoT on a complex reasoning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing different reasoning approaches on a complex logic puzzle:\n",
      "================================================================================\n",
      "Question: \n",
      "A group of friends - Alice, Bob, Charlie, and Diana - are solving a puzzle that requires arranging 4 colored balls (red, blue, green, yellow) in a specific order.\n",
      "Given these clues:\n",
      "1. The red ball comes before the blue ball, but not immediately before.\n",
      "2. The yellow ball is either the first or the last.\n",
      "3. Charlie's ball is immediately after Diana's ball.\n",
      "4. Alice has the green ball, and Bob doesn't have a ball at either end.\n",
      "\n",
      "What is the correct order of the balls from left to right, and who has which ball?\n",
      "\n",
      "\n",
      "\n",
      "1. Regular Prompting:\n",
      "----------------------------------------\n",
      "To solve the puzzle, let's analyze the clues step by step.\n",
      "\n",
      "1. **Clue 1**: The red ball comes before the blue ball, but not immediately before. This means there must be at least one ball between the red and blue balls.\n",
      "\n",
      "2. **Clue 2**: The yellow ball is either the first or the last. This gives us two possible positions for the yellow ball: position 1 or position 4.\n",
      "\n",
      "3. **Clue 3**: Charlie's ball is immediately after Diana's ball. This means if Diana has a ball in position X, Charlie must have a ball in position X+1.\n",
      "\n",
      "4. **Clue 4**: Alice has the green ball, and Bob doesn't have a ball at either end. This means Bob cannot be in position 1 or position 4.\n",
      "\n",
      "Now, let's analyze the possibilities based on these clues:\n",
      "\n",
      "### Case 1: Yellow ball is in position 1\n",
      "- If yellow is in position 1, Bob cannot be in position 1 or 4, so he must be in position 2 or 3. \n",
      "- This means Alice (green) must be in position 3 or 4. But if Alice is in position 4, then Bob must be in position 3, which violates the clue that red must come before blue (since blue must be in position 4). Thus, this case is not possible.\n",
      "\n",
      "### Case 2: Yellow ball is in position 4\n",
      "- If yellow is in position 4, then Bob must be in position 2 or 3. \n",
      "- Alice must then be in position 1 or 2. Since Bob can't be at either end, he must be in position 3, which means Alice is in position 2.\n",
      "- This leaves position 1 for Diana, and position 3 for Bob, and position 2 for Alice (green).\n",
      "- The arrangement so far is:\n",
      "  - Position 1: Diana\n",
      "  - Position 2: Alice (green)\n",
      "  - Position 3: Bob\n",
      "  - Position 4: Yellow\n",
      "\n",
      "Now we need to assign the balls:\n",
      "- Since Alice has the green ball, Diana can have either red or blue, and Bob can have either red or blue.\n",
      "- The red ball must come before the blue ball but not immediately before, so if Diana has the red ball, Bob must have the blue ball.\n",
      "\n",
      "Now we have:\n",
      "- Position \n",
      "\n",
      "2. Chain of Thought:\n",
      "----------------------------------------\n",
      "Let me think through this step by step:\n",
      "\n",
      "1. **Understand what the question is asking**: We need to determine the correct order of the colored balls (red, blue, green, yellow) and identify which friend (Alice, Bob, Charlie, Diana) has which ball based on the given clues.\n",
      "\n",
      "2. **Identify the key information and constraints**:\n",
      "   - Clue 1: The red ball comes before the blue ball, but not immediately before (meaning there must be at least one ball between red and blue).\n",
      "   - Clue 2: The yellow ball is either the first or the last in the arrangement.\n",
      "   - Clue 3: Charlie's ball is immediately after Diana's ball.\n",
      "   - Clue 4: Alice has the green ball, and Bob doesn't have a ball at either end (meaning Bob cannot have the first or last ball).\n",
      "\n",
      "3. **Consider different approaches to solve the problem**:\n",
      "   - Start by placing the yellow ball in the first or last position based on Clue 2.\n",
      "   - Use the information about Alice having the green ball to place her ball.\n",
      "   - Use Clue 3 to determine the positions of Charlie and Diana's balls relative to each other.\n",
      "   - Finally, ensure that the arrangement satisfies all the clues.\n",
      "\n",
      "4. **Walk through the solution step by step**:\n",
      "   - **Step 1**: Place the yellow ball. It can either be in position 1 or position 4.\n",
      "     - If yellow is in position 1, Bob cannot be in position 2 or 3 (since he can't be at either end), which means he must be in position 4. This would leave positions 2 and 3 for Alice (green) and the red and blue balls, which contradicts the clues. Thus, yellow cannot be in position 1.\n",
      "     - Therefore, yellow must be in position 4.\n",
      "   \n",
      "   - **Step 2**: Now we have:\n",
      "     ```\n",
      "     1: ?\n",
      "     2: ?\n",
      "     3: ?\n",
      "     4: Yellow\n",
      "     ```\n",
      "   - **Step 3**: Since Bob cannot be at either end, he must be in position 2 or 3. He cannot be in position 4 (which is yellow), so he must be in position 2 or 3.\n",
      "   - **Step 4**: Since Alice has the green ball and Bob cannot be in position 1 or 4, Alice must be in position 1 or 3. If Alice is in position 1, then Bob must be in position 2, leaving position 3 for the red and blue balls.\n",
      "   - **Step 5**: If Alice is in position 1 with the green ball, we can assume:\n",
      "     ```\n",
      "     1: Green (Alice)\n",
      "     2: ?\n",
      "     3: ?\n",
      "     4: Yellow\n",
      "     ```\n",
      "   - **Step 6**: Since Charlie's ball is immediately after Diana's ball (Clue 3), and Bob is in position 2 or 3, we can place Bob in position 2, which leaves position 3 for either Charlie or Diana. \n",
      "   - **Step 7**: If Bob is in position 2, he must have the blue ball (since red must come before blue). This means Diana must be in position 3 with the red ball, and Charlie must be in position 4 with the yellow ball.\n",
      "   - **Step 8**: The arrangement now looks like this:\n",
      "     ```\n",
      "     1: Green (Alice)\n",
      "     2: Blue (Bob)\n",
      "     3: Red (Diana)\n",
      "     4: Yellow (Charlie)\n",
      "     ```\n",
      "   - **Step 9**: However, we need to ensure that the red ball comes before the blue ball, which contradicts our arrangement. Thus, we need to re-evaluate.\n",
      "\n",
      "5.\n",
      "\n",
      "3. Few-Shot Chain of Thought:\n",
      "----------------------------------------\n",
      "Let's analyze the clues step by step to determine the correct order of the balls and who has which ball.\n",
      "\n",
      "1. **Clue 1**: The red ball comes before the blue ball, but not immediately before.\n",
      "   - This means there must be at least one ball between the red and blue balls.\n",
      "\n",
      "2. **Clue 2**: The yellow ball is either the first or the last.\n",
      "   - This gives us two possible positions for the yellow ball: position 1 or position 4.\n",
      "\n",
      "3. **Clue 3**: Charlie's ball is immediately after Diana's ball.\n",
      "   - This means if Diana has a ball in position X, Charlie has a ball in position X+1.\n",
      "\n",
      "4. **Clue 4**: Alice has the green ball, and Bob doesn't have a ball at either end.\n",
      "   - Since Bob cannot have the first or last ball, he must have one of the middle positions (2 or 3).\n",
      "\n",
      "Now, let's start placing the balls based on these clues:\n",
      "\n",
      "### Case Analysis\n",
      "\n",
      "**Case 1**: Yellow ball is in position 1.\n",
      "- Positions: [Yellow, _, _, _]\n",
      "- Bob cannot be in position 1 or 4, so he must be in position 2 or 3.\n",
      "- If Bob is in position 2, then Alice must be in position 3 (since she has the green ball), and Charlie must be in position 4 (because Diana must be in position 3). This contradicts Clue 3.\n",
      "- If Bob is in position 3, then Alice must be in position 2. This also contradicts Clue 3 because Charlie cannot be in position 4 (since Diana would have to be in position 3).\n",
      "\n",
      "**Case 2**: Yellow ball is in position 4.\n",
      "- Positions: [_, _, _, Yellow]\n",
      "- Bob can only be in positions 2 or 3.\n",
      "- If Bob is in position 2, then Alice must be in position 3. This means Diana must be in position 1, and Charlie must be in position 2, which contradicts Clue 3.\n",
      "- If Bob is in position 3, then Alice must be in position 2. This means Diana must be in position 1, and Charlie must be in position 2, which again contradicts Clue 3.\n",
      "\n",
      "### Working with Clue 3\n",
      "Since Charlie's ball is immediately after Diana's ball, we can deduce that Diana cannot be in position 4 (because there would be no position for Charlie). \n",
      "\n",
      "### Final Arrangement\n",
      "1. **Assuming Yellow is in position 4**:\n",
      "   - If Diana is in position 1, then Charlie must be in position 2.\n",
      "   - This leaves positions 3 for Alice (green) and 4 for Bob.\n",
      "   - The only color left for Bob is blue, and the only color left for Charlie is red.\n",
      "\n",
      "Thus, the arrangement is:\n",
      "- Position 1: Diana (Red)\n",
      "- Position 2: Charlie (Green)\n",
      "- Position 3: Alice (Blue)\n",
      "- Position 4: Bob (Yellow)\n",
      "\n",
      "### Conclusion\n",
      "The final order of the balls from left to right is:\n",
      "1. Diana - Red\n",
      "2. Charlie - Green\n",
      "3. Alice - Blue\n",
      "4. Bob - Yellow\n",
      "\n",
      "This satisfies all the clues provided.\n"
     ]
    }
   ],
   "source": [
    "def regular_prompt(question: str, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> str:\n",
    "    \"\"\"A baseline approach without explicit reasoning instructions.\"\"\"\n",
    "    response = call_openrouter(\n",
    "        prompt=question,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    if response.get(\"success\", False):\n",
    "        return extract_text_response(response)\n",
    "    else:\n",
    "        return f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "\n",
    "# A more complex reasoning question\n",
    "complex_question = \"\"\"\n",
    "A group of friends - Alice, Bob, Charlie, and Diana - are solving a puzzle that requires arranging 4 colored balls (red, blue, green, yellow) in a specific order.\n",
    "Given these clues:\n",
    "1. The red ball comes before the blue ball, but not immediately before.\n",
    "2. The yellow ball is either the first or the last.\n",
    "3. Charlie's ball is immediately after Diana's ball.\n",
    "4. Alice has the green ball, and Bob doesn't have a ball at either end.\n",
    "\n",
    "What is the correct order of the balls from left to right, and who has which ball?\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nComparing different reasoning approaches on a complex logic puzzle:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Question: {complex_question}\\n\")\n",
    "\n",
    "print(\"\\n1. Regular Prompting:\")\n",
    "print(\"-\" * 40)\n",
    "regular_response = regular_prompt(complex_question)\n",
    "print(regular_response)\n",
    "\n",
    "print(\"\\n2. Chain of Thought:\")\n",
    "print(\"-\" * 40)\n",
    "cot_response = chain_of_thought(complex_question)\n",
    "print(cot_response)\n",
    "\n",
    "print(\"\\n3. Few-Shot Chain of Thought:\")\n",
    "print(\"-\" * 40)\n",
    "few_shot_response = few_shot_cot(complex_question)\n",
    "print(few_shot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ReAct Pattern Implementation\n",
    "\n",
    "The ReAct (Reasoning+Acting) pattern combines reasoning with action to tackle complex tasks. Let's implement this pattern from scratch without relying on libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 First, Let's Define Some Tools\n",
    "\n",
    "We'll create a few simple tools that our ReAct agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Wikipedia-like search tool\n",
    "def search_wiki(query: str) -> str:\n",
    "    \"\"\"Simulates a Wikipedia search.\"\"\"\n",
    "    # In a real application, this would call a search API\n",
    "    wiki_db = {\n",
    "        \"python\": \"Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability. Python is dynamically typed and garbage-collected. It was created by Guido van Rossum in 1991. Key features include significant whitespace, dynamic typing, and automatic memory management.\",\n",
    "        \"neural network\": \"A neural network is a series of algorithms that endeavors to recognize relationships in a dataset through a process that mimics how the human brain operates. Neural networks are a set of algorithms modeled loosely after the human brain, designed to recognize patterns. They interpret sensory data through machine perception, labeling, or clustering raw input.\",\n",
    "        \"machine learning\": \"Machine learning is a branch of artificial intelligence and computer science that focuses on using data and algorithms to imitate the way that humans learn, gradually improving its accuracy. The primary aim is to develop computer systems that can learn from data without being explicitly programmed.\",\n",
    "        \"quantum computing\": \"Quantum computing is a type of computation that harnesses the collective properties of quantum states, such as superposition, interference, and entanglement, to perform calculations. The devices that perform quantum computations are known as quantum computers.\",\n",
    "        \"climate change\": \"Climate change refers to significant, long-term changes in the global climate. The primary cause is human activities, particularly the burning of fossil fuels, which adds heat-trapping gases to Earth's atmosphere. The consequences include rising temperatures, extreme weather events, shifting wildlife populations and habitats, rising seas, and more.\"\n",
    "    }\n",
    "    \n",
    "    # Simple keyword matching\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    for key, value in wiki_db.items():\n",
    "        if key in query_lower or query_lower in key:\n",
    "            results.append(f\"Entry: {key.title()}\\n{value}\")\n",
    "    \n",
    "    if results:\n",
    "        return \"\\n\\n\".join(results)\n",
    "    else:\n",
    "        return f\"No results found for '{query}'. Try a different search term.\"\n",
    "\n",
    "# Calculator tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        # Warning: eval can be dangerous in production environments\n",
    "        # For a real application, use a safer approach\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}. Please check the expression format.\"\n",
    "\n",
    "# Data lookup tool\n",
    "def lookup_data(dataset: str, query: str) -> str:\n",
    "    \"\"\"Looks up information in a specified dataset.\"\"\"\n",
    "    # Simulated datasets\n",
    "    datasets = {\n",
    "        \"countries\": {\n",
    "            \"usa\": {\"capital\": \"Washington D.C.\", \"population\": \"331 million\", \"currency\": \"US Dollar\"},\n",
    "            \"japan\": {\"capital\": \"Tokyo\", \"population\": \"126 million\", \"currency\": \"Japanese Yen\"},\n",
    "            \"germany\": {\"capital\": \"Berlin\", \"population\": \"83 million\", \"currency\": \"Euro\"},\n",
    "            \"nigeria\": {\"capital\": \"Abuja\", \"population\": \"211 million\", \"currency\": \"Nigerian Naira\"},\n",
    "            \"brazil\": {\"capital\": \"Brasilia\", \"population\": \"214 million\", \"currency\": \"Brazilian Real\"}\n",
    "        },\n",
    "        \"planets\": {\n",
    "            \"mercury\": {\"position\": 1, \"type\": \"Terrestrial\", \"moons\": 0, \"rings\": \"No\"},\n",
    "            \"venus\": {\"position\": 2, \"type\": \"Terrestrial\", \"moons\": 0, \"rings\": \"No\"},\n",
    "            \"earth\": {\"position\": 3, \"type\": \"Terrestrial\", \"moons\": 1, \"rings\": \"No\"},\n",
    "            \"mars\": {\"position\": 4, \"type\": \"Terrestrial\", \"moons\": 2, \"rings\": \"No\"},\n",
    "            \"jupiter\": {\"position\": 5, \"type\": \"Gas Giant\", \"moons\": 79, \"rings\": \"Yes\"},\n",
    "            \"saturn\": {\"position\": 6, \"type\": \"Gas Giant\", \"moons\": 82, \"rings\": \"Yes\"},\n",
    "            \"uranus\": {\"position\": 7, \"type\": \"Ice Giant\", \"moons\": 27, \"rings\": \"Yes\"},\n",
    "            \"neptune\": {\"position\": 8, \"type\": \"Ice Giant\", \"moons\": 14, \"rings\": \"Yes\"}\n",
    "        },\n",
    "        \"elements\": {\n",
    "            \"hydrogen\": {\"symbol\": \"H\", \"atomic number\": 1, \"category\": \"Nonmetal\"},\n",
    "            \"helium\": {\"symbol\": \"He\", \"atomic number\": 2, \"category\": \"Noble gas\"},\n",
    "            \"carbon\": {\"symbol\": \"C\", \"atomic number\": 6, \"category\": \"Nonmetal\"},\n",
    "            \"oxygen\": {\"symbol\": \"O\", \"atomic number\": 8, \"category\": \"Nonmetal\"},\n",
    "            \"gold\": {\"symbol\": \"Au\", \"atomic number\": 79, \"category\": \"Transition metal\"},\n",
    "            \"uranium\": {\"symbol\": \"U\", \"atomic number\": 92, \"category\": \"Actinide\"}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    if dataset.lower() not in datasets:\n",
    "        return f\"Dataset '{dataset}' not found. Available datasets: {', '.join(datasets.keys())}\"\n",
    "    \n",
    "    data = datasets[dataset.lower()]\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Check if specific item is requested\n",
    "    for key, value in data.items():\n",
    "        if query_lower == key or query_lower in key:\n",
    "            result = [f\"{key.title()}:\"] \n",
    "            for attr, val in value.items():\n",
    "                result.append(f\"- {attr.title()}: {val}\")\n",
    "            return \"\\n\".join(result)\n",
    "    \n",
    "    # If no specific item matched, return a list of available items\n",
    "    return f\"No specific item '{query}' found in '{dataset}'. Available items: {', '.join(data.keys())}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Raw ReAct Implementation\n",
    "\n",
    "Now, let's implement the ReAct pattern from scratch, combining reasoning and acting in a cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the population of the capital of Japan?\n",
      "\n",
      "ReAct Reasoning Steps:\n",
      "\n",
      "Step 1:\n",
      "1. Think: I need to find the current population of the capital of Japan, which is Tokyo. A good starting point would be to look up Tokyo's population in a reliable source like a Wikipedia-like database.\n",
      "\n",
      "2. Action: ACTION: search_wiki(\"Tokyo population\")\n",
      "\n",
      "3. Observation: I will now check the search results for Tokyo's population.\n",
      "\n",
      "4. Continue this process until I find the answer. \n",
      "\n",
      "Let's perform the search now. \n",
      "\n",
      "ACTION: search_wiki(\"Tokyo population\")\n",
      "\n",
      "OBSERVATION: Error executing search_wiki: search_wiki() missing 1 required positional argument: 'query'\n",
      "\n",
      "Step 2:\n",
      "1. Think: It seems there was an error in executing the search. I need to ensure that I use the correct format for the tool. I will try the search again, making sure to properly specify the query.\n",
      "\n",
      "2. Action: ACTION: search_wiki(query=\"Tokyo population\")\n",
      "\n",
      "3. Observation: I will now check the search results for Tokyo's population.\n",
      "\n",
      "Let's perform the search now. \n",
      "\n",
      "ACTION: search_wiki(query=\"Tokyo population\")\n",
      "\n",
      "OBSERVATION: No results found for 'Tokyo population'. Try a different search term.\n",
      "\n",
      "Step 3:\n",
      "1. Think: Since the search for \"Tokyo population\" did not yield results, I should try a broader search term. I will look up information on Tokyo instead, which should include details about its population.\n",
      "\n",
      "2. Action: ACTION: search_wiki(query=\"Tokyo\")\n",
      "\n",
      "3. Observation: I will now check the search results for information about Tokyo, which should include its population.\n",
      "\n",
      "Let's perform the search now. \n",
      "\n",
      "ACTION: search_wiki(query=\"Tokyo\")\n",
      "\n",
      "OBSERVATION: No results found for 'Tokyo'. Try a different search term.\n",
      "\n",
      "Step 4:\n",
      "1. Think: Given that my previous searches for \"Tokyo\" and \"Tokyo population\" did not yield results, I need to consider another tool. I can look up data in the dataset available on countries, which might provide me with the capital's information, including population.\n",
      "\n",
      "2. Action: ACTION: lookup_data(dataset=\"countries\", query=\"Japan\")\n",
      "\n",
      "3. Observation: I will now check the results to find information about Japan's capital and its population.\n",
      "\n",
      "Let's perform the lookup now. \n",
      "\n",
      "ACTION: lookup_data(dataset=\"countries\", query=\"Japan\")\n",
      "\n",
      "OBSERVATION: Japan:\n",
      "- Capital: Tokyo\n",
      "- Population: 126 million\n",
      "- Currency: Japanese Yen\n",
      "\n",
      "Step 5:\n",
      "1. Think: I have successfully obtained the information about Japan, including that its capital is Tokyo and that the population is 126 million. This is the information I need to answer the question.\n",
      "\n",
      "2. Observation: I can now summarize the findings to provide a complete answer to the question.\n",
      "\n",
      "FINAL ANSWER: The population of the capital of Japan, Tokyo, is approximately 126 million.\n",
      "\n",
      "Final Answer:\n",
      "The population of the capital of Japan, Tokyo, is approximately 126 million.\n"
     ]
    }
   ],
   "source": [
    "def raw_react(question: str, tools: Dict[str, Callable], max_iterations: int = 5, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Tuple[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"Implements the ReAct pattern from scratch without specialized libraries.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        tools: Dictionary mapping tool names to functions\n",
    "        max_iterations: Maximum number of reasoning-action cycles\n",
    "        model: LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final answer, list of reasoning-action steps)\n",
    "    \"\"\"\n",
    "    # Initial prompt explaining the format and available tools\n",
    "    initial_prompt = f\"\"\"\n",
    "    You are an AI assistant that can use tools to answer questions. Follow these steps for each iteration:\n",
    "    \n",
    "    1. Think: Consider what information you need and what tools could help.\n",
    "    2. Action: Choose a tool to use in the format: ACTION: tool_name(parameter1=\"value\", parameter2=\"value\")\n",
    "    3. Observation: Review the result of the tool use.\n",
    "    4. Continue this process until you can answer the question.\n",
    "    \n",
    "    When you have the answer, respond with: FINAL ANSWER: your complete answer here\n",
    "    \n",
    "    Available tools:\n",
    "    - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "    - calculator(expression): Evaluate a mathematical expression\n",
    "    - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Begin your reasoning process now.\n",
    "    \"\"\"\n",
    "    \n",
    "    current_prompt = initial_prompt\n",
    "    iterations = []\n",
    "    final_answer = \"\"\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Get the model's reasoning and action\n",
    "        response = call_openrouter(\n",
    "            prompt=current_prompt,\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        \n",
    "        if not response.get(\"success\", False):\n",
    "            return f\"Error: {response.get('error', 'Unknown error')}\", iterations\n",
    "        \n",
    "        reasoning = extract_text_response(response)\n",
    "        \n",
    "        # Check if we have a final answer\n",
    "        if \"FINAL ANSWER:\" in reasoning:\n",
    "            # Extract the final answer\n",
    "            final_answer = reasoning.split(\"FINAL ANSWER:\")[1].strip()\n",
    "            iterations.append({\"reasoning\": reasoning, \"type\": \"final\"})\n",
    "            break\n",
    "        \n",
    "        # Extract the action from the reasoning\n",
    "        action_match = re.search(r'ACTION:\\s*(\\w+)\\((.+?)\\)', reasoning)\n",
    "        if not action_match:\n",
    "            # No action found, prompt for a proper action\n",
    "            current_prompt += f\"\\n\\n{reasoning}\\n\\nPlease specify an action in the format: ACTION: tool_name(parameter1=\\\"value\\\", parameter2=\\\"value\\\"), or provide a final answer.\"\n",
    "            iterations.append({\"reasoning\": reasoning, \"type\": \"no_action\"})\n",
    "            continue\n",
    "        \n",
    "        tool_name = action_match.group(1).strip()\n",
    "        args_str = action_match.group(2).strip()\n",
    "        \n",
    "        # Parse the arguments\n",
    "        args = {}\n",
    "        # Handle named arguments in the format parameter=\"value\"\n",
    "        for arg_match in re.finditer(r'(\\w+)\\s*=\\s*\"([^\"]*)\"|\\s*(\\w+)\\s*=\\s*\\'([^\\']*)\\'', args_str):\n",
    "            if arg_match.group(1):\n",
    "                arg_name = arg_match.group(1)\n",
    "                arg_value = arg_match.group(2)\n",
    "            else:\n",
    "                arg_name = arg_match.group(3)\n",
    "                arg_value = arg_match.group(4)\n",
    "            args[arg_name] = arg_value\n",
    "        \n",
    "        # Execute the tool if it exists\n",
    "        if tool_name in tools:\n",
    "            try:\n",
    "                tool_result = tools[tool_name](**args)\n",
    "                observation = f\"OBSERVATION: {tool_result}\"\n",
    "            except Exception as e:\n",
    "                observation = f\"OBSERVATION: Error executing {tool_name}: {str(e)}\"\n",
    "        else:\n",
    "            observation = f\"OBSERVATION: Tool '{tool_name}' not found. Available tools: {', '.join(tools.keys())}\"\n",
    "        \n",
    "        # Add the reasoning, action, and observation to the prompt\n",
    "        current_prompt += f\"\\n\\n{reasoning}\\n\\n{observation}\\n\\nContinue your reasoning based on this observation:\"\n",
    "        \n",
    "        # Record this iteration\n",
    "        iterations.append({\n",
    "            \"reasoning\": reasoning,\n",
    "            \"action\": {\"tool\": tool_name, \"args\": args},\n",
    "            \"observation\": observation,\n",
    "            \"type\": \"action\"\n",
    "        })\n",
    "    \n",
    "    # If we've reached max iterations without a final answer, ask for one\n",
    "    if not final_answer:\n",
    "        current_prompt += \"\\n\\nYou've reached the maximum number of iterations. Please provide your final answer now.\"\n",
    "        \n",
    "        response = call_openrouter(\n",
    "            prompt=current_prompt,\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        if response.get(\"success\", False):\n",
    "            final_reasoning = extract_text_response(response)\n",
    "            \n",
    "            # Try to extract a final answer if formatted correctly\n",
    "            if \"FINAL ANSWER:\" in final_reasoning:\n",
    "                final_answer = final_reasoning.split(\"FINAL ANSWER:\")[1].strip()\n",
    "            else:\n",
    "                # Otherwise use the whole response\n",
    "                final_answer = final_reasoning\n",
    "                \n",
    "            iterations.append({\"reasoning\": final_reasoning, \"type\": \"final\"})\n",
    "        else:\n",
    "            final_answer = f\"Error getting final answer: {response.get('error', 'Unknown error')}\"\n",
    "    \n",
    "    return final_answer, iterations\n",
    "\n",
    "# Define our tools dictionary\n",
    "tools_dict = {\n",
    "    \"search_wiki\": search_wiki,\n",
    "    \"calculator\": calculator,\n",
    "    \"lookup_data\": lookup_data\n",
    "}\n",
    "\n",
    "# Test the raw ReAct implementation\n",
    "question1 = \"What is the population of the capital of Japan?\"\n",
    "answer1, steps1 = raw_react(question1, tools_dict)\n",
    "\n",
    "print(f\"Question: {question1}\\n\")\n",
    "print(\"ReAct Reasoning Steps:\")\n",
    "for i, step in enumerate(steps1):\n",
    "    print(f\"\\nStep {i+1}:\")\n",
    "    print(step[\"reasoning\"])\n",
    "    if step[\"type\"] == \"action\":\n",
    "        print(\"\\n\" + step[\"observation\"])\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another example with a more complex question that will require multiple tool uses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If I have 3 hydrogen atoms and 5 carbon atoms, how many electrons do I have in total?\n",
      "\n",
      "ReAct Reasoning Steps:\n",
      "\n",
      "Step 1:\n",
      "1. Think: To determine the total number of electrons, I need to know how many electrons are associated with each type of atom. Hydrogen has 1 electron per atom, and carbon has 6 electrons per atom. \n",
      "\n",
      "2. Action: I will calculate the total number of electrons by using the formula: (number of hydrogen atoms * electrons per hydrogen) + (number of carbon atoms * electrons per carbon).\n",
      "\n",
      "   The expression is: (3 * 1) + (5 * 6).\n",
      "\n",
      "   ACTION: calculator((3 * 1) + (5 * 6))\n",
      "\n",
      "3. Observation: Now I will evaluate the result of the calculation.\n",
      "\n",
      "4. Continuing the process: \n",
      "\n",
      "After performing the calculation, we get:\n",
      "\n",
      "- Electrons from hydrogen: 3 * 1 = 3 electrons \n",
      "- Electrons from carbon: 5 * 6 = 30 electrons \n",
      "\n",
      "Adding these together gives 3 + 30 = 33 electrons.\n",
      "\n",
      "FINAL ANSWER: You have a total of 33 electrons.\n",
      "\n",
      "Final Answer:\n",
      "You have a total of 33 electrons.\n"
     ]
    }
   ],
   "source": [
    "question2 = \"If I have 3 hydrogen atoms and 5 carbon atoms, how many electrons do I have in total?\"\n",
    "answer2, steps2 = raw_react(question2, tools_dict)\n",
    "\n",
    "print(f\"Question: {question2}\\n\")\n",
    "print(\"ReAct Reasoning Steps:\")\n",
    "for i, step in enumerate(steps2):\n",
    "    print(f\"\\nStep {i+1}:\")\n",
    "    print(step[\"reasoning\"])\n",
    "    if step[\"type\"] == \"action\":\n",
    "        print(\"\\n\" + step[\"observation\"])\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Planning-Execution Loop\n",
    "\n",
    "Now let's implement a planning-execution loop from scratch. This pattern first creates a plan and then executes each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which planet has more moons, Jupiter or Saturn, and how many does each have?\n",
      "\n",
      "Generated Plan:\n",
      "Step 1: Gather information about the number of moons for Jupiter.\n",
      "Tool: lookup_data\n",
      "Parameters: planets, \"Jupiter\"\n",
      "\n",
      "Step 2: Gather information about the number of moons for Saturn.\n",
      "Tool: lookup_data\n",
      "Parameters: planets, \"Saturn\"\n",
      "\n",
      "Step 3: Compare the number of moons between Jupiter and Saturn.\n",
      "Tool: None\n",
      "Parameters: None\n",
      "Purpose: To determine which planet has more moons based on the data retrieved in the previous steps.\n",
      "\n",
      "Step 4: Compile the results into a clear answer format.\n",
      "Tool: None\n",
      "Parameters: None\n",
      "Purpose: To present the findings in a concise manner, stating which planet has more moons and the specific counts for each.\n",
      "\n",
      "Execution Results:\n",
      "\n",
      "Step 1:\n",
      "Tool: lookup_data\n",
      "Arguments: {'dataset': 'planets', 'query': 'Jupiter'}\n",
      "Status: success\n",
      "Result: Jupiter:\n",
      "- Position: 5\n",
      "- Type: Gas Giant\n",
      "- Moons: 79\n",
      "- Rings: Yes\n",
      "\n",
      "Step 3:\n",
      "Tool: lookup_data\n",
      "Arguments: {}\n",
      "Status: failed\n",
      "Error: lookup_data() missing 2 required positional arguments: 'dataset' and 'query'\n",
      "\n",
      "Final Answer:\n",
      "As of the latest data, Jupiter has 79 moons, while Saturn has 83 moons. Therefore, Saturn has more moons than Jupiter. Here’s a summary of the findings:\n",
      "\n",
      "- **Jupiter**: 79 moons\n",
      "- **Saturn**: 83 moons\n",
      "\n",
      "In conclusion, Saturn has more moons than Jupiter.\n"
     ]
    }
   ],
   "source": [
    "def planning_execution_loop(question: str, tools: Dict[str, Callable], model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"Implements a planning-execution loop from scratch.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        tools: Dictionary mapping tool names to functions\n",
    "        model: LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final answer, dict with plan and execution details)\n",
    "    \"\"\"\n",
    "    # Step 1: Generate a plan\n",
    "    planning_prompt = f\"\"\"\n",
    "    You are an AI assistant that creates detailed plans to answer questions.\n",
    "    \n",
    "    Available tools:\n",
    "    - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "    - calculator(expression): Evaluate a mathematical expression\n",
    "    - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Create a step-by-step plan to answer this question. For each step, specify:\n",
    "    1. The tool to use (if any)\n",
    "    2. The exact parameters to pass to the tool\n",
    "    3. The purpose of this step\n",
    "    \n",
    "    Format each step as:\n",
    "    \n",
    "    Step 1: [Purpose of this step]\n",
    "    Tool: [tool_name or None]\n",
    "    Parameters: [parameters for the tool, if applicable]\n",
    "    \n",
    "    Step 2: ...\n",
    "    \n",
    "    Make sure your plan is comprehensive and will lead to a complete answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_response = call_openrouter(\n",
    "        prompt=planning_prompt,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    if not planning_response.get(\"success\", False):\n",
    "        return f\"Error in planning: {planning_response.get('error', 'Unknown error')}\", {\"error\": planning_response.get('error')}\n",
    "    \n",
    "    plan = extract_text_response(planning_response)\n",
    "    \n",
    "    # Step 2: Parse the plan into executable steps\n",
    "    # This is a simple parser that looks for Step N: patterns\n",
    "    step_pattern = r'Step\\s+(\\d+):(.*?)(?:Step\\s+\\d+:|$)'  \n",
    "    step_matches = re.finditer(step_pattern, plan, re.DOTALL)\n",
    "    \n",
    "    parsed_steps = []\n",
    "    for match in step_matches:\n",
    "        step_num = match.group(1)\n",
    "        step_content = match.group(2).strip()\n",
    "        \n",
    "        # Extract tool and parameters\n",
    "        tool_match = re.search(r'Tool:\\s*([\\w\\s]+)', step_content, re.IGNORECASE)\n",
    "        param_match = re.search(r'Parameters:\\s*(.*?)(?:$|\\n\\n)', step_content, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        tool = tool_match.group(1).strip() if tool_match else None\n",
    "        params = param_match.group(1).strip() if param_match else None\n",
    "        \n",
    "        # Skip steps with no tool (informational steps)\n",
    "        if tool and tool.lower() != \"none\":\n",
    "            parsed_steps.append({\n",
    "                \"step_num\": int(step_num),\n",
    "                \"content\": step_content,\n",
    "                \"tool\": tool,\n",
    "                \"params\": params\n",
    "            })\n",
    "    \n",
    "    # Step 3: Execute each step in the plan\n",
    "    execution_results = []\n",
    "    tool_outputs = {}\n",
    "    \n",
    "    for step in parsed_steps:\n",
    "        # Prepare execution prompt\n",
    "        execution_prompt = f\"\"\"\n",
    "        You are an AI assistant that executes specific steps in a plan.\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Current step to execute: {step['content']}\n",
    "        \n",
    "        You need to extract the exact tool name and parameters from this step. \n",
    "        Return ONLY the tool call in this format: TOOL: tool_name(parameter1=\"value\", parameter2=\"value\")\n",
    "        \n",
    "        Available tools:\n",
    "        - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "        - calculator(expression): Evaluate a mathematical expression\n",
    "        - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "        \"\"\"\n",
    "        \n",
    "        execution_response = call_openrouter(\n",
    "            prompt=execution_prompt,\n",
    "            model=model,\n",
    "            temperature=0.3,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        if not execution_response.get(\"success\", False):\n",
    "            execution_results.append({\n",
    "                \"step\": step,\n",
    "                \"error\": execution_response.get('error', 'Unknown error'),\n",
    "                \"status\": \"failed\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        tool_call = extract_text_response(execution_response)\n",
    "        \n",
    "        # Extract the tool and parameters\n",
    "        tool_match = re.search(r'TOOL:\\s*(\\w+)\\((.+?)\\)', tool_call)\n",
    "        if not tool_match:\n",
    "            execution_results.append({\n",
    "                \"step\": step,\n",
    "                \"error\": \"Could not parse tool call\",\n",
    "                \"tool_call\": tool_call,\n",
    "                \"status\": \"failed\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        tool_name = tool_match.group(1).strip()\n",
    "        args_str = tool_match.group(2).strip()\n",
    "        \n",
    "        # Parse the arguments\n",
    "        args = {}\n",
    "        for arg_match in re.finditer(r'(\\w+)\\s*=\\s*\"([^\"]*)\"|\\s*(\\w+)\\s*=\\s*\\'([^\\']*)\\'', args_str):\n",
    "            if arg_match.group(1):\n",
    "                arg_name = arg_match.group(1)\n",
    "                arg_value = arg_match.group(2)\n",
    "            else:\n",
    "                arg_name = arg_match.group(3)\n",
    "                arg_value = arg_match.group(4)\n",
    "            args[arg_name] = arg_value\n",
    "        \n",
    "        # Execute the tool\n",
    "        if tool_name in tools:\n",
    "            try:\n",
    "                tool_result = tools[tool_name](**args)\n",
    "                step_key = f\"step_{step['step_num']}\"\n",
    "                tool_outputs[step_key] = tool_result\n",
    "                \n",
    "                execution_results.append({\n",
    "                    \"step\": step,\n",
    "                    \"tool\": tool_name,\n",
    "                    \"args\": args,\n",
    "                    \"result\": tool_result,\n",
    "                    \"status\": \"success\"\n",
    "                })\n",
    "            except Exception as e:\n",
    "                execution_results.append({\n",
    "                    \"step\": step,\n",
    "                    \"tool\": tool_name,\n",
    "                    \"args\": args,\n",
    "                    \"error\": str(e),\n",
    "                    \"status\": \"failed\"\n",
    "                })\n",
    "        else:\n",
    "            execution_results.append({\n",
    "                \"step\": step,\n",
    "                \"tool\": tool_name,\n",
    "                \"error\": f\"Tool '{tool_name}' not found\",\n",
    "                \"status\": \"failed\"\n",
    "            })\n",
    "    \n",
    "    # Step 4: Synthesize the results into a final answer\n",
    "    synthesis_prompt = f\"\"\"\n",
    "    You are an AI assistant that synthesizes information to answer questions.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Plan:\n",
    "    {plan}\n",
    "    \n",
    "    Execution Results:\n",
    "    {\"..\".join([f\"Step {result['step']['step_num']}: {result['step']['content']}..Result: {result.get('result', result.get('error', 'No result'))}\" for result in execution_results])}\n",
    "    \n",
    "    Based on these results, provide a comprehensive answer to the original question.\n",
    "    \"\"\"\n",
    "    \n",
    "    synthesis_response = call_openrouter(\n",
    "        prompt=synthesis_prompt,\n",
    "        model=model,\n",
    "        temperature=0.5,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not synthesis_response.get(\"success\", False):\n",
    "        return f\"Error in synthesis: {synthesis_response.get('error', 'Unknown error')}\", {\n",
    "            \"plan\": plan,\n",
    "            \"execution_results\": execution_results,\n",
    "            \"error\": synthesis_response.get('error')\n",
    "        }\n",
    "    \n",
    "    final_answer = extract_text_response(synthesis_response)\n",
    "    \n",
    "    return final_answer, {\n",
    "        \"plan\": plan,\n",
    "        \"execution_results\": execution_results,\n",
    "        \"tool_outputs\": tool_outputs\n",
    "    }\n",
    "\n",
    "# Test the planning-execution loop\n",
    "planning_question = \"Which planet has more moons, Jupiter or Saturn, and how many does each have?\"\n",
    "planning_answer, planning_details = planning_execution_loop(planning_question, tools_dict)\n",
    "\n",
    "print(f\"Question: {planning_question}\\n\")\n",
    "print(\"Generated Plan:\")\n",
    "print(planning_details[\"plan\"])\n",
    "print(\"\\nExecution Results:\")\n",
    "for i, result in enumerate(planning_details[\"execution_results\"]):\n",
    "    print(f\"\\nStep {result['step']['step_num']}:\")\n",
    "    print(f\"Tool: {result.get('tool', 'Unknown')}\")\n",
    "    print(f\"Arguments: {result.get('args', 'None')}\")\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    if 'result' in result:\n",
    "        print(f\"Result: {result['result']}\")\n",
    "    elif 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(planning_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflection and Self-Correction Mechanisms\n",
    "\n",
    "Let's implement a reflection mechanism that allows the agent to recognize and correct its own mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting initial answer...\n",
      "Reflecting on initial answer...\n",
      "Corrections needed. Performing a second reasoning pass...\n",
      "\n",
      "Question: If Saturn has 82 moons and Jupiter has 79 moons, what percentage more moons does Saturn have compared to Jupiter?\n",
      "\n",
      "Initial Answer:\n",
      "Saturn has approximately 3.8% more moons than Jupiter.\n",
      "\n",
      "Reflection:\n",
      "REFLECTION:\n",
      "The reasoning process is mostly correct, but there is a significant error in the calculation of the percentage. The steps to find the difference in the number of moons and to express that difference as a percentage of Jupiter's moons are correctly outlined. However, the calculator action should yield a different result than what was stated as the final answer.\n",
      "\n",
      "Let's break it down:\n",
      "\n",
      "1. The difference in the number of moons is calculated correctly: \n",
      "   - 82 (Saturn) - 79 (Jupiter) = 3 moons.\n",
      "\n",
      "2. To find the percentage more moons Saturn has compared to Jupiter, the formula used is correct:\n",
      "   - Percentage more = (Difference / Jupiter's moons) * 100\n",
      "   - This translates to (3 / 79) * 100.\n",
      "\n",
      "3. The calculation itself was not shown, but assuming it was performed correctly, the result should be:\n",
      "   - (3 / 79) * 100 ≈ 3.79746835, which rounds to approximately 3.8%.\n",
      "\n",
      "However, the final answer stated that Saturn has \"approximately 3.8% more moons than Jupiter,\" which is misleading because it implies that Saturn has 3.8% of Jupiter's total moons, rather than indicating that Saturn has 3.8% more moons than Jupiter. The phrasing should clarify that Saturn has 3.8% more than Jupiter's total.\n",
      "\n",
      "4. The final answer should clearly specify that it is the percentage increase in the number of moons, not just a comparison without context.\n",
      "\n",
      "CORRECTIONS NEEDED: Yes\n",
      "\n",
      "IMPROVED ANSWER: Saturn has approximately 3.8% more moons than Jupiter, based on the calculation that Saturn has 3 more moons than Jupiter, which is about 3.8% of Jupiter's total number of moons.\n",
      "\n",
      "Final Answer:\n",
      "To determine how many percentage more moons Saturn has compared to Jupiter, we can follow these steps carefully:\n",
      "\n",
      "1. **Calculate the difference in the number of moons**:\n",
      "   - Saturn has 82 moons.\n",
      "   - Jupiter has 79 moons.\n",
      "   - The difference in the number of moons is:\n",
      "     \\[\n",
      "     82 - 79 = 3 \\text{ moons}\n",
      "     \\]\n",
      "\n",
      "2. **Calculate the percentage more moons Saturn has compared to Jupiter**:\n",
      "   - We want to find out what percentage the difference (3 moons) is of Jupiter's moons (79 moons).\n",
      "   - The formula for calculating the percentage increase is:\n",
      "     \\[\n",
      "     \\text{Percentage more} = \\left( \\frac{\\text{Difference}}{\\text{Jupiter's moons}} \\right) \\times 100\n",
      "     \\]\n",
      "   - Plugging in the values we have:\n",
      "     \\[\n",
      "     \\text{Percentage more} = \\left( \\frac{3}{79} \\right) \\times 100\n",
      "     \\]\n",
      "\n",
      "3. **Perform the calculation**:\n",
      "   - First, calculate \\( \\frac{3}{79} \\):\n",
      "     \\[\n",
      "     \\frac{3}{79} \\approx 0.03797468354\n",
      "     \\]\n",
      "   - Now, multiply by 100 to get the percentage:\n",
      "     \\[\n",
      "     0.03797468354 \\times 100 \\approx 3.797468353 \\text{ (approximately 3.8%)}\n",
      "     \\]\n",
      "\n",
      "4. **Final answer and clarification**:\n",
      "   - Thus, Saturn has approximately **3.8% more moons than Jupiter**. \n",
      "   - It's important to clarify that this percentage reflects the increase in the number of moons Saturn has compared to Jupiter's total, not just a simple comparison of the numbers.\n",
      "\n",
      "In conclusion, Saturn has approximately **3.8% more moons than Jupiter**.\n"
     ]
    }
   ],
   "source": [
    "def reflective_agent(question: str, tools: Dict[str, Callable], model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"An agent that can reflect on and correct its own reasoning.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        tools: Dictionary mapping tool names to functions\n",
    "        model: LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final answer, dict with reflection details)\n",
    "    \"\"\"\n",
    "    # First, get an initial answer using the ReAct pattern\n",
    "    print(\"Getting initial answer...\")\n",
    "    initial_answer, steps = raw_react(question, tools, max_iterations=3, model=model)\n",
    "    \n",
    "    # Prepare a prompt that shows the full reasoning process\n",
    "    reasoning_process = \"\"\n",
    "    for i, step in enumerate(steps):\n",
    "        reasoning_process += f\"\\nStep {i+1}:\\n{step['reasoning']}\\n\"\n",
    "        if step[\"type\"] == \"action\" and \"observation\" in step:\n",
    "            reasoning_process += f\"{step['observation']}\\n\"\n",
    "    \n",
    "    # Reflection prompt\n",
    "    reflection_prompt = f\"\"\"\n",
    "    You are an AI assistant that can reflect on and correct reasoning.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Below is a reasoning process that led to an answer. Carefully analyze this reasoning for errors, \n",
    "    missing steps, or faulty logic. Then provide a reflection that identifies any issues and suggests improvements.\n",
    "    \n",
    "    Reasoning Process:\n",
    "    {reasoning_process}\n",
    "    \n",
    "    Initial Answer: {initial_answer}\n",
    "    \n",
    "    Reflection Instructions:\n",
    "    1. Identify any errors or flaws in the reasoning\n",
    "    2. Note any missing information or steps that should have been taken\n",
    "    3. Assess whether the final answer is correct and complete\n",
    "    4. Suggest specific improvements to the reasoning process\n",
    "    \n",
    "    Format your reflection as follows:\n",
    "    \n",
    "    REFLECTION:\n",
    "    [Your detailed reflection here]\n",
    "    \n",
    "    CORRECTIONS NEEDED: [Yes/No]\n",
    "    \n",
    "    IMPROVED ANSWER: [Provide a corrected answer only if corrections are needed]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reflecting on initial answer...\")\n",
    "    reflection_response = call_openrouter(\n",
    "        prompt=reflection_prompt,\n",
    "        model=model,\n",
    "        temperature=0.5,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not reflection_response.get(\"success\", False):\n",
    "        return f\"Error in reflection: {reflection_response.get('error', 'Unknown error')}\", {\"error\": reflection_response.get('error')}\n",
    "    \n",
    "    reflection = extract_text_response(reflection_response)\n",
    "    \n",
    "    # Extract whether corrections are needed\n",
    "    corrections_match = re.search(r'CORRECTIONS NEEDED:\\s*(Yes|No)', reflection, re.IGNORECASE)\n",
    "    corrections_needed = False\n",
    "    if corrections_match:\n",
    "        corrections_needed = corrections_match.group(1).lower() == \"yes\"\n",
    "    \n",
    "    # Extract the improved answer if available\n",
    "    improved_answer = initial_answer\n",
    "    improved_match = re.search(r'IMPROVED ANSWER:\\s*(.*?)(?:$)', reflection, re.DOTALL)\n",
    "    if improved_match and corrections_needed:\n",
    "        improved_answer = improved_match.group(1).strip()\n",
    "    \n",
    "    # If there are still issue, do a second pass with more specific instructions\n",
    "    if corrections_needed:\n",
    "        print(\"Corrections needed. Performing a second reasoning pass...\")\n",
    "        \n",
    "        # Extract reflection content\n",
    "        reflection_content = \"\"\n",
    "        reflection_match = re.search(r'REFLECTION:\\s*(.*?)(?:CORRECTIONS NEEDED:|$)', reflection, re.DOTALL)\n",
    "        if reflection_match:\n",
    "            reflection_content = reflection_match.group(1).strip()\n",
    "        \n",
    "        # Create a new prompt with the reflection as guidance\n",
    "        improved_prompt = f\"\"\"\n",
    "        You are an AI assistant answering a user's question with careful reasoning.\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        A previous attempt to answer this question had some issues. Here's a reflection on those issues:\n",
    "        \n",
    "        {reflection_content}\n",
    "        \n",
    "        With this feedback in mind, approach the question again. Use the available tools if needed:\n",
    "        - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "        - calculator(expression): Evaluate a mathematical expression\n",
    "        - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "        \n",
    "        Show your complete reasoning process and provide a correct, comprehensive answer.\n",
    "        \"\"\"\n",
    "        \n",
    "        final_response = call_openrouter(\n",
    "            prompt=improved_prompt,\n",
    "            model=model,\n",
    "            temperature=0.5,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        \n",
    "        if final_response.get(\"success\", False):\n",
    "            final_answer = extract_text_response(final_response)\n",
    "        else:\n",
    "            final_answer = f\"Error in final correction: {final_response.get('error', 'Unknown error')}\"\n",
    "    else:\n",
    "        # No corrections needed, use the improved or initial answer\n",
    "        final_answer = improved_answer\n",
    "    \n",
    "    return final_answer, {\n",
    "        \"initial_answer\": initial_answer,\n",
    "        \"reflection\": reflection,\n",
    "        \"corrections_needed\": corrections_needed,\n",
    "        \"improved_answer\": improved_answer,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "# Test the reflective agent with a question that might have reasoning flaws\n",
    "reflection_question = \"If Saturn has 82 moons and Jupiter has 79 moons, what percentage more moons does Saturn have compared to Jupiter?\"\n",
    "reflection_answer, reflection_details = reflective_agent(reflection_question, tools_dict)\n",
    "\n",
    "print(f\"\\nQuestion: {reflection_question}\\n\")\n",
    "print(\"Initial Answer:\")\n",
    "print(reflection_details[\"initial_answer\"])\n",
    "print(\"\\nReflection:\")\n",
    "print(reflection_details[\"reflection\"])\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(reflection_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combining Multiple Reasoning Frameworks\n",
    "\n",
    "Now, let's combine multiple reasoning frameworks into a single, powerful agent. This agent will use:\n",
    "\n",
    "1. Chain of Thought to break down problems\n",
    "2. Planning to create a structured approach\n",
    "3. ReAct to dynamically interact with tools\n",
    "4. Reflection to catch and correct errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Problem Analysis using Chain of Thought\n",
      "Step 2: Creating a structured plan\n",
      "Step 3: Executing the plan using ReAct\n",
      "Step 4: Reflecting on the result\n",
      "\n",
      "Question: If Earth has 1 moon, Mars has 2 moons, Jupiter has 79 moons, and Saturn has 82 moons, what is the average number of moons per planet for these 4 planets?\n",
      "\n",
      "Problem Analysis:\n",
      "### Analysis of the Problem\n",
      "\n",
      "1. **Core Question**: \n",
      "   The core question is asking for the average number of moons per planet for Earth, Mars, Jupiter, and Saturn. \n",
      "\n",
      "2. **Information Needed**: \n",
      "   To calculate the average number of moons per planet, we need:\n",
      "   - The total number of moons for each o...\n",
      "\n",
      "Plan:\n",
      "### Step-by-Step Plan to Calculate the Average Number of Moons per Planet\n",
      "\n",
      "1. **Step 1: Gather Moon Data for Each Planet**\n",
      "   - **Purpose**: To collect the number of moons for Earth, Mars, Jupiter, and Saturn.\n",
      "   - **Tool Needed**: `lookup_data(planets, query)` (to retrieve moon counts).\n",
      "   - **Expe...\n",
      "\n",
      "Execution Result:\n",
      "The average number of moons per planet for Earth, Mars, Jupiter, and Saturn is 41 moons.\n",
      "\n",
      "Reflection:\n",
      "REFLECTION:\n",
      "1. The answer is complete and directly responds to the question by providing the average number of moons per planet.\n",
      "2. There are no errors in the reasoning or calculations. The steps taken to arrive at the answer are sound and logically structured.\n",
      "3. The answer is presented clearly and...\n",
      "\n",
      "Final Answer:\n",
      "The average number of moons per planet for Earth, Mars, Jupiter, and Saturn is 41 moons.\n"
     ]
    }
   ],
   "source": [
    "def combined_reasoning_agent(question: str, tools: Dict[str, Callable], model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"An agent that combines multiple reasoning frameworks.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        tools: Dictionary mapping tool names to functions\n",
    "        model: LLM model to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final answer, dict with process details)\n",
    "    \"\"\"\n",
    "    # Step 1: Use Chain of Thought to break down the problem\n",
    "    print(\"Step 1: Problem Analysis using Chain of Thought\")\n",
    "    cot_prompt = f\"\"\"\n",
    "    You are an AI assistant that breaks down problems step by step.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Before jumping into the solution, carefully analyze the problem:\n",
    "    1. What is the core question being asked?\n",
    "    2. What information do we need to answer it?\n",
    "    3. What potential approaches could we take?\n",
    "    4. Are there any potential complications or edge cases?\n",
    "    \n",
    "    Structure your analysis clearly.\n",
    "    \"\"\"\n",
    "    \n",
    "    cot_response = call_openrouter(\n",
    "        prompt=cot_prompt,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not cot_response.get(\"success\", False):\n",
    "        return f\"Error in problem analysis: {cot_response.get('error', 'Unknown error')}\", {\"error\": cot_response.get('error')}\n",
    "    \n",
    "    problem_analysis = extract_text_response(cot_response)\n",
    "    \n",
    "    # Step 2: Create a plan based on the analysis\n",
    "    print(\"Step 2: Creating a structured plan\")\n",
    "    planning_prompt = f\"\"\"\n",
    "    You are an AI assistant that creates clear, structured plans.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Problem Analysis:\n",
    "    {problem_analysis}\n",
    "    \n",
    "    Based on this analysis, create a step-by-step plan to answer the question.\n",
    "    For each step, specify:\n",
    "    1. The purpose of the step\n",
    "    2. Whether a tool is needed (and if so, which one)\n",
    "    3. What we expect to learn from this step\n",
    "    \n",
    "    Available tools:\n",
    "    - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "    - calculator(expression): Evaluate a mathematical expression\n",
    "    - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "    \n",
    "    Format your plan as numbered steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_response = call_openrouter(\n",
    "        prompt=planning_prompt,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not planning_response.get(\"success\", False):\n",
    "        return f\"Error in planning: {planning_response.get('error', 'Unknown error')}\", {\n",
    "            \"problem_analysis\": problem_analysis,\n",
    "            \"error\": planning_response.get('error')\n",
    "        }\n",
    "    \n",
    "    plan = extract_text_response(planning_response)\n",
    "    \n",
    "    # Step 3: Execute the plan using ReAct\n",
    "    print(\"Step 3: Executing the plan using ReAct\")\n",
    "    react_prompt = f\"\"\"\n",
    "    You are an AI assistant that follows plans while being flexible enough to adapt when needed.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Problem Analysis:\n",
    "    {problem_analysis}\n",
    "    \n",
    "    Plan:\n",
    "    {plan}\n",
    "    \n",
    "    Your task is to execute this plan step by step. For each step:\n",
    "    1. Think about what needs to be done\n",
    "    2. Use tools when needed in the format: ACTION: tool_name(parameter1=\"value\", parameter2=\"value\")\n",
    "    3. Review the results and continue to the next step\n",
    "    \n",
    "    Available tools:\n",
    "    - search_wiki(query): Search for information in a Wikipedia-like database\n",
    "    - calculator(expression): Evaluate a mathematical expression\n",
    "    - lookup_data(dataset, query): Look up information in a dataset (available datasets: countries, planets, elements)\n",
    "    \n",
    "    When you have the final answer, respond with: FINAL ANSWER: your complete answer here\n",
    "    \n",
    "    Begin executing the plan now.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use our raw_react function to execute this\n",
    "    react_answer, react_steps = raw_react(react_prompt, tools, max_iterations=5, model=model)\n",
    "    \n",
    "    # Extract the final answer from the ReAct execution\n",
    "    if \"FINAL ANSWER:\" in react_answer:\n",
    "        execution_result = react_answer.split(\"FINAL ANSWER:\")[1].strip()\n",
    "    else:\n",
    "        execution_result = react_answer\n",
    "    \n",
    "    # Step 4: Reflect on the result\n",
    "    print(\"Step 4: Reflecting on the result\")\n",
    "    reflection_prompt = f\"\"\"\n",
    "    You are an AI assistant that carefully reviews and improves answers.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Problem Analysis:\n",
    "    {problem_analysis}\n",
    "    \n",
    "    Plan:\n",
    "    {plan}\n",
    "    \n",
    "    Execution Result:\n",
    "    {execution_result}\n",
    "    \n",
    "    Please review this answer critically:\n",
    "    1. Is the answer complete and directly responding to the question?\n",
    "    2. Are there any errors in the reasoning or calculations?\n",
    "    3. Is the answer presented clearly and concisely?\n",
    "    4. Are there any important details or considerations missing?\n",
    "    \n",
    "    If improvements are needed, provide a revised answer that addresses any issues.\n",
    "    \n",
    "    Format your response as:\n",
    "    \n",
    "    REFLECTION:\n",
    "    [Your reflection here]\n",
    "    \n",
    "    REVISED ANSWER:\n",
    "    [The improved answer, or \"The original answer is correct and complete.\" if no changes are needed]\n",
    "    \"\"\"\n",
    "    \n",
    "    reflection_response = call_openrouter(\n",
    "        prompt=reflection_prompt,\n",
    "        model=model,\n",
    "        temperature=0.5,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not reflection_response.get(\"success\", False):\n",
    "        return execution_result, {\n",
    "            \"problem_analysis\": problem_analysis,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result,\n",
    "            \"react_steps\": react_steps,\n",
    "            \"reflection_error\": reflection_response.get('error')\n",
    "        }\n",
    "    \n",
    "    reflection = extract_text_response(reflection_response)\n",
    "    \n",
    "    # Extract the revised answer\n",
    "    revised_match = re.search(r'REVISED ANSWER:\\s*(.*?)(?:$)', reflection, re.DOTALL)\n",
    "    if revised_match:\n",
    "        revised_answer = revised_match.group(1).strip()\n",
    "        if \"original answer is correct\" in revised_answer.lower():\n",
    "            final_answer = execution_result\n",
    "        else:\n",
    "            final_answer = revised_answer\n",
    "    else:\n",
    "        final_answer = execution_result\n",
    "    \n",
    "    return final_answer, {\n",
    "        \"problem_analysis\": problem_analysis,\n",
    "        \"plan\": plan,\n",
    "        \"execution_result\": execution_result,\n",
    "        \"reflection\": reflection,\n",
    "        \"react_steps\": react_steps\n",
    "    }\n",
    "\n",
    "# Test the combined reasoning agent\n",
    "combined_question = \"If Earth has 1 moon, Mars has 2 moons, Jupiter has 79 moons, and Saturn has 82 moons, what is the average number of moons per planet for these 4 planets?\"\n",
    "\n",
    "combined_answer, combined_details = combined_reasoning_agent(combined_question, tools_dict)\n",
    "\n",
    "print(f\"\\nQuestion: {combined_question}\\n\")\n",
    "print(\"Problem Analysis:\")\n",
    "print(combined_details[\"problem_analysis\"][:300] + \"...\" if len(combined_details[\"problem_analysis\"]) > 300 else combined_details[\"problem_analysis\"])\n",
    "print(\"\\nPlan:\")\n",
    "print(combined_details[\"plan\"][:300] + \"...\" if len(combined_details[\"plan\"]) > 300 else combined_details[\"plan\"])\n",
    "print(\"\\nExecution Result:\")\n",
    "print(combined_details[\"execution_result\"])\n",
    "print(\"\\nReflection:\")\n",
    "print(combined_details[\"reflection\"][:300] + \"...\" if len(combined_details[\"reflection\"]) > 300 else combined_details[\"reflection\"])\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(combined_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Best Practices\n",
    "\n",
    "In this notebook, we've implemented several advanced reasoning frameworks from scratch without relying on specialized libraries:\n",
    "\n",
    "1. **Chain of Thought (CoT)**: Encouraging step-by-step reasoning through prompt engineering\n",
    "2. **ReAct Pattern**: Interleaving reasoning and action steps for dynamic problem-solving\n",
    "3. **Planning-Execution Loop**: Creating a plan first, then executing each step methodically\n",
    "4. **Reflection and Self-Correction**: Adding a review phase to identify and fix reasoning errors\n",
    "5. **Combined Reasoning**: Integrating multiple frameworks for comprehensive problem-solving\n",
    "\n",
    "### Best Practices for Implementing Reasoning Frameworks\n",
    "\n",
    "1. **Clear Instructions**: Provide explicit formatting requirements in your prompts\n",
    "2. **Structured Output**: Use consistent patterns (e.g., \"ACTION:\", \"FINAL ANSWER:\") for easier parsing\n",
    "3. **Robust Parsing**: Use flexible regex patterns to handle variations in model outputs\n",
    "4. **Error Handling**: Add fallbacks when parsing or tool execution fails\n",
    "5. **Iterative Development**: Start simple and add complexity gradually\n",
    "6. **Context Management**: Be mindful of prompt length to avoid exceeding context windows\n",
    "7. **Temperature Settings**: Use lower temperature (0.0-0.3) for reasoning tasks, higher (0.5-0.7) for creative synthesis\n",
    "8. **Model Selection**: More capable models generally perform better at complex reasoning\n",
    "\n",
    "### When to Use Each Framework\n",
    "\n",
    "- **Chain of Thought**: Use for math problems, logic puzzles, and other tasks requiring step-by-step reasoning\n",
    "- **ReAct**: Best for exploratory tasks where the path isn't clear and interactive tools are needed\n",
    "- **Planning-Execution**: Ideal for complex, multi-step tasks with a predictable workflow\n",
    "- **Reflection**: Add when accuracy is critical and the cost of errors is high\n",
    "- **Combined Approaches**: Use for the most challenging problems where a single approach may not be sufficient\n",
    "\n",
    "By implementing these patterns from scratch, you gain a deeper understanding of how they work and can customize them for your specific use cases, without being constrained by library limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
