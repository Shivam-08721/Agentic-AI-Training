{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Architecture Patterns\n",
    "\n",
    "This notebook explores different architectural patterns for building AI agents with Large Language Models (LLMs). We'll cover:\n",
    "\n",
    "- Single-turn vs. multi-turn agents\n",
    "- Tools vs. augmented prompt approaches\n",
    "- Planning-focused architectures\n",
    "- Action-focused architectures\n",
    "- Hybrid approaches and when to use them\n",
    "\n",
    "We'll implement examples of each pattern to understand their advantages, limitations, and best use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's install the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: tenacity in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (9.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumi\\anaconda3\\envs\\general_use\\lib\\site-packages (from requests) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv requests tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully!\n",
      "API key: sk-...843\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directory to path to import utility functions\n",
    "sys.path.append('../../Week1/Day2')\n",
    "\n",
    "# Import our API utilities\n",
    "from api_utils import (\n",
    "    call_openrouter,\n",
    "    extract_text_response,\n",
    "    extract_function_call,\n",
    "    get_available_models\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✅ API key loaded successfully!\")\n",
    "    # Show first and last three characters for verification\n",
    "    masked_key = f\"{api_key[:3]}...{api_key[-3:]}\" if len(api_key) > 6 else \"[key too short]\"\n",
    "    print(f\"API key: {masked_key}\")\n",
    "else:\n",
    "    print(\"❌ API key not found! Make sure you've created a .env file with your OPENROUTER_API_KEY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Agent Architectures\n",
    "\n",
    "Before diving into specific patterns, let's understand what an LLM agent is and the core components that make up an agent architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What is an LLM Agent?\n",
    "\n",
    "LLM-based agents (or LLM agents) are applications that can execute complex tasks through an architecture combining large language models with key modules like planning, memory, and tool usage. In these systems, the LLM serves as the main controller or \"brain\" that orchestrates the flow of operations needed to complete a task or user request.\n",
    "\n",
    "Core components of agent architectures typically include:\n",
    "\n",
    "1. **LLM Core**: The primary language model that processes inputs, generates outputs, and makes decisions.\n",
    "2. **Memory Systems**: Both short-term (within a conversation) and long-term (across sessions) memory.\n",
    "3. **Tools/Functions**: External capabilities the agent can use to interact with the world.\n",
    "4. **Planning Module**: The ability to break down complex tasks into manageable steps.\n",
    "5. **Reasoning Engine**: The ability to think through problems and make logical decisions.\n",
    "6. **Action Executor**: The component that carries out actions in the external world.\n",
    "\n",
    "Not all agents require all of these components, and the specific architecture you choose depends on your use case requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single-Turn vs. Multi-Turn Agents\n",
    "\n",
    "One of the most fundamental distinctions in agent architectures is between single-turn and multi-turn agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Single-Turn Agents\n",
    "\n",
    "Single-turn agents complete tasks with just one interaction between the user and the LLM. They receive a prompt, process it, and deliver the final output without any intermediate steps or additional interaction.\n",
    "\n",
    "**Advantages:**\n",
    "- Simplicity of implementation\n",
    "- Lower latency (faster response time)\n",
    "- Lower cost (single LLM call)\n",
    "- Predictable behavior\n",
    "\n",
    "**Limitations:**\n",
    "- Limited ability to solve complex problems\n",
    "- No feedback loop to correct misunderstandings\n",
    "- No ability to access external tools or information beyond prompt\n",
    "- Fixed context window limitations\n",
    "\n",
    "Let's implement a simple single-turn agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the three laws of robotics?\n",
      "\n",
      "Response: The Three Laws of Robotics, formulated by science fiction writer Isaac Asimov, are:\n",
      "\n",
      "1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.\n",
      "2. A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.\n",
      "3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\n"
     ]
    }
   ],
   "source": [
    "def single_turn_agent(user_input: str, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> str:\n",
    "    \"\"\"A simple single-turn agent that processes a user query and returns a response.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's query\n",
    "        model: The model to use for processing\n",
    "        \n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    # System instructions define the agent's behavior\n",
    "    system_instructions = \"\"\"\n",
    "    You are a helpful AI assistant. Answer the user's question directly and concisely.\n",
    "    If you don't know the answer, say so rather than making something up.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a single API call\n",
    "    response = call_openrouter(\n",
    "        prompt=user_input,\n",
    "        model=model,\n",
    "        system_prompt=system_instructions,\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract and return the text response\n",
    "    if response.get(\"success\", False):\n",
    "        return extract_text_response(response)\n",
    "    else:\n",
    "        return f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "\n",
    "# Test the single-turn agent\n",
    "query = \"What are the three laws of robotics?\"\n",
    "result = single_turn_agent(query)\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Response: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multi-Turn Agents\n",
    "\n",
    "Multi-turn agents engage in an iterative process, with multiple interactions between the agent and its environment (which could include the user, tools, or external systems) before producing a final output.\n",
    "\n",
    "**Advantages:**\n",
    "- Can solve more complex problems through iteration\n",
    "- Can leverage external tools and information sources\n",
    "- Can correct misunderstandings through feedback\n",
    "- Can adapt strategy based on intermediate results\n",
    "\n",
    "**Limitations:**\n",
    "- Higher latency (slower response time)\n",
    "- Higher cost (multiple LLM calls)\n",
    "- More complex implementation\n",
    "- Potential for getting stuck in loops\n",
    "\n",
    "Let's implement a basic multi-turn agent with conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is machine learning?\n",
      "Agent: Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead, these systems learn from data by identifying patterns and making predictions or decisions based on that data. Machine learning is commonly used in applications such as image and speech recognition, natural language processing, and recommendation systems.\n",
      "\n",
      "User: What are some popular algorithms for it?\n",
      "Agent: Some popular machine learning algorithms include:\n",
      "\n",
      "1. **Linear Regression**: Used for predicting a continuous target variable based on one or more predictors.\n",
      "\n",
      "2. **Logistic Regression**: Used for binary classification problems to predict the probability of an outcome.\n",
      "\n",
      "3. **Decision Trees**: A flowchart-like structure used for both classification and regression tasks.\n",
      "\n",
      "4. **Random Forest**: An ensemble method that uses multiple decision trees to improve accuracy and reduce overfitting.\n",
      "\n",
      "5. **Support Vector Machines (SVM)**: Used for classification tasks by finding the hyperplane that best separates different classes.\n",
      "\n",
      "6. **K-Nearest Neighbors (KNN)**: A simple, instance-based learning algorithm used for classification and regression.\n",
      "\n",
      "7. **Neural Networks**: Models inspired by the human brain, used for complex tasks like image and speech recognition.\n",
      "\n",
      "8. **Gradient Boosting Machines (GBM)**: An ensemble technique that builds models in a sequential manner, often yielding high predictive performance.\n",
      "\n",
      "9. **Naive Bayes**: A probabilistic classifier based on applying Bayes' theorem with strong independence assumptions.\n",
      "\n",
      "These algorithms can be applied to various tasks, depending on the nature of the data and the specific problem being addressed.\n"
     ]
    }
   ],
   "source": [
    "def multi_turn_agent(user_input: str, conversation_history: List[Dict[str, str]] = None, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> tuple:\n",
    "    \"\"\"A multi-turn agent that maintains conversation history.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's query\n",
    "        conversation_history: List of previous message dictionaries\n",
    "        model: The model to use for processing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (agent response, updated conversation history)\n",
    "    \"\"\"\n",
    "    # Initialize conversation history if it doesn't exist\n",
    "    if conversation_history is None:\n",
    "        conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are a helpful AI assistant. Maintain context throughout the conversation.\n",
    "                Answer the user's questions directly and concisely. If you don't know the answer, say so rather than making something up.\n",
    "                Use information from previous messages when relevant.\"\"\"},\n",
    "        ]\n",
    "    \n",
    "    # Add user input to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Make API call with full conversation history\n",
    "    response = call_openrouter(\n",
    "        prompt=conversation_history,\n",
    "        model=model,\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract text response\n",
    "    if response.get(\"success\", False):\n",
    "        assistant_response = extract_text_response(response)\n",
    "        # Add assistant response to conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        return assistant_response, conversation_history\n",
    "    else:\n",
    "        error_message = f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "        return error_message, conversation_history\n",
    "\n",
    "# Test the multi-turn agent with multiple interactions\n",
    "# Initialize conversation\n",
    "history = None\n",
    "\n",
    "# First interaction\n",
    "query1 = \"What is machine learning?\"\n",
    "response1, history = multi_turn_agent(query1, history)\n",
    "\n",
    "print(f\"User: {query1}\")\n",
    "print(f\"Agent: {response1}\\n\")\n",
    "\n",
    "# Second interaction (referencing the first)\n",
    "query2 = \"What are some popular algorithms for it?\"\n",
    "response2, history = multi_turn_agent(query2, history)\n",
    "\n",
    "print(f\"User: {query2}\")\n",
    "print(f\"Agent: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tools vs. Augmented Prompt Approaches\n",
    "\n",
    "There are two main ways for LLM agents to extend their capabilities: using tools or augmenting prompts with external information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Tool-Based Agents\n",
    "\n",
    "Tool-based agents can call external functions or APIs to perform actions or retrieve information. These tools extend the agent's capabilities beyond what's possible with the LLM alone.\n",
    "\n",
    "**Advantages:**\n",
    "- Can interact with external systems and data sources\n",
    "- Can perform real-world actions (like sending emails, booking appointments)\n",
    "- Not limited by the LLM's knowledge cutoff\n",
    "- Can handle structured data processing\n",
    "\n",
    "**Limitations:**\n",
    "- More complex to implement and maintain\n",
    "- Requires careful security and permission management\n",
    "- May introduce additional latency from external API calls\n",
    "- Requires predefined tools for specific tasks\n",
    "\n",
    "Let's define some tools and implement a basic tool-using agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some simple tools\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Simulated weather lookup tool.\"\"\"\n",
    "    # In a real application, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"new york\": \"72°F, Partly Cloudy\",\n",
    "        \"london\": \"61°F, Rainy\",\n",
    "        \"tokyo\": \"78°F, Sunny\",\n",
    "        \"sydney\": \"65°F, Windy\"\n",
    "    }\n",
    "    return weather_data.get(location.lower(), \"Weather data not available for this location\")\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Simple calculator tool.\"\"\"\n",
    "    try:\n",
    "        # Warning: eval can be dangerous in production environments\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "# Define the tools in the format expected by the LLM\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city name, e.g., 'New York', 'London'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Perform a mathematical calculation\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The mathematical expression to evaluate, e.g., '2 + 2', '3 * 4 / 2'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather like in London?\n",
      "Agent: The weather in London is currently 61°F and rainy.\n",
      "\n",
      "User: What's the result of 123 * 456?\n",
      "Agent: The result of 123 * 456 is 56,088.\n",
      "\n",
      "User: What are some popular tourist attractions in Paris?\n",
      "Agent: Some popular tourist attractions in Paris include:\n",
      "\n",
      "1. **Eiffel Tower** - An iconic symbol of Paris, offering stunning views of the city.\n",
      "2. **Louvre Museum** - The world's largest art museum, home to thousands of works including the Mona Lisa.\n",
      "3. **Notre-Dame Cathedral** - A masterpiece of French Gothic architecture, located on the Île de la Cité.\n",
      "4. **Champs-Élysées and Arc de Triomphe** - A famous avenue leading to the monumental arch honoring those who fought for France.\n",
      "5. **Montmartre and Sacré-Cœur Basilica** - A historic district known for its artistic history and the stunning basilica at its summit.\n",
      "6. **Seine River Cruises** - Offering a unique perspective of the city's landmarks along the river.\n",
      "7. **Palace of Versailles** - A short trip from Paris, this opulent palace is known for its gardens and Hall of Mirrors.\n",
      "8. **Musée d'Orsay** - An art museum housed in a former railway station, featuring Impressionist masterpieces.\n",
      "9. **Luxembourg Gardens** - A beautiful park perfect for relaxation and enjoying nature.\n",
      "10. **Sainte-Chapelle** - Known for its stunning stained glass windows, this Gothic chapel is a hidden gem.\n",
      "\n",
      "These attractions offer a mix of history, art, culture, and stunning architecture.\n"
     ]
    }
   ],
   "source": [
    "def tool_using_agent(user_input: str, conversation_history: List[Dict[str, str]] = None, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> tuple:\n",
    "    \"\"\"An agent that can use tools to respond to user queries.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's query\n",
    "        conversation_history: List of previous message dictionaries\n",
    "        model: The model to use for processing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (agent response, updated conversation history)\n",
    "    \"\"\"\n",
    "    # Initialize conversation history if it doesn't exist\n",
    "    if conversation_history is None:\n",
    "        conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are a helpful AI assistant that can use tools to provide information.\n",
    "                When you need specific information, use the appropriate tool. If a user's request can be answered\n",
    "                using one of your tools, use the tool rather than providing a generic response.\n",
    "                For weather information, use the get_weather tool.\n",
    "                For calculations, use the calculate tool.\"\"\"}\n",
    "        ]\n",
    "    \n",
    "    # Add user input to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Make API call with tools configuration\n",
    "    response = call_openrouter(\n",
    "        prompt=conversation_history,\n",
    "        model=model,\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "        functions=tools  # Include our defined tools\n",
    "    )\n",
    "    \n",
    "    if response.get(\"success\", False):\n",
    "        # Check if the model wants to call a function\n",
    "        function_call = extract_function_call(response)\n",
    "        \n",
    "        if function_call.get(\"success\", False):\n",
    "            # The model wants to use a tool\n",
    "            function_name = function_call.get(\"function_name\")\n",
    "            arguments = function_call.get(\"arguments\", {})\n",
    "            tool_id = function_call.get(\"tool_id\", \"call_\" + str(uuid.uuid4()))\n",
    "            \n",
    "            # Execute the requested function\n",
    "            if function_name == \"get_weather\":\n",
    "                tool_result = get_weather(arguments.get(\"location\", \"\"))\n",
    "            elif function_name == \"calculate\":\n",
    "                tool_result = calculate(arguments.get(\"expression\", \"\"))\n",
    "            else:\n",
    "                tool_result = f\"Error: Unknown function '{function_name}'\"\n",
    "                \n",
    "            # Add the tool call and result to conversation history using the new format\n",
    "            conversation_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": None,\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tool_id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": function_name,\n",
    "                            \"arguments\": json.dumps(arguments)\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_id,\n",
    "                \"content\": tool_result\n",
    "            })\n",
    "            \n",
    "            # Make a second API call to get the assistant's final response\n",
    "            second_response = call_openrouter(\n",
    "                prompt=conversation_history,\n",
    "                model=model,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            if second_response.get(\"success\", False):\n",
    "                assistant_response = extract_text_response(second_response)\n",
    "                conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "                return assistant_response, conversation_history\n",
    "            else:\n",
    "                error_message = f\"Error in second call: {second_response.get('error', 'Unknown error')}\"\n",
    "                return error_message, conversation_history\n",
    "        else:\n",
    "            # No function call, just a regular response\n",
    "            assistant_response = extract_text_response(response)\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            return assistant_response, conversation_history\n",
    "    else:\n",
    "        error_message = f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "        return error_message, conversation_history\n",
    "\n",
    "# Test the tool-using agent\n",
    "# Try a weather query\n",
    "weather_query = \"What's the weather like in London?\"\n",
    "weather_response, history = tool_using_agent(weather_query)\n",
    "\n",
    "print(f\"User: {weather_query}\")\n",
    "print(f\"Agent: {weather_response}\\n\")\n",
    "\n",
    "# Try a calculation query\n",
    "calc_query = \"What's the result of 123 * 456?\"\n",
    "calc_response, history = tool_using_agent(calc_query, history)\n",
    "\n",
    "print(f\"User: {calc_query}\")\n",
    "print(f\"Agent: {calc_response}\\n\")\n",
    "\n",
    "# Try a general query that doesn't need tools\n",
    "general_query = \"What are some popular tourist attractions in Paris?\"\n",
    "general_response, history = tool_using_agent(general_query, history)\n",
    "\n",
    "print(f\"User: {general_query}\")\n",
    "print(f\"Agent: {general_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Augmented Prompt Approaches (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is an alternative approach that enhances LLM capabilities by retrieving relevant information and including it in the prompt, rather than using external tools.\n",
    "\n",
    "**Advantages:**\n",
    "- Simpler implementation (no complex tool interaction logic)\n",
    "- Can be done in a single LLM call (potentially lower latency)\n",
    "- Can incorporate domain-specific knowledge without custom tool development\n",
    "- More flexible and adaptable to new information sources\n",
    "\n",
    "**Limitations:**\n",
    "- Limited by context window size\n",
    "- Cannot perform actions, only retrieve information\n",
    "- Information retrieval quality depends on embedding and retrieval methods\n",
    "- May lead to inconsistent results based on retrieval quality\n",
    "\n",
    "Let's implement a simple RAG agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple knowledge base for demonstration\n",
    "knowledge_base = {\n",
    "    \"company_info\": \"\"\"\n",
    "    TechCorp was founded in 2010 by Jane Smith and John Doe.\n",
    "    Headquarters: San Francisco, CA\n",
    "    Number of employees: 1,200\n",
    "    Annual revenue: $250 million\n",
    "    Main products: Cloud software, AI solutions, and data analytics tools\n",
    "    CEO: Dr. Jane Smith\n",
    "    CTO: Dr. John Doe\n",
    "    \"\"\",\n",
    "    \n",
    "    \"product_info\": \"\"\"\n",
    "    TechCloud: Our flagship cloud computing platform\n",
    "    - Price: Starting at $99/month for business tier\n",
    "    - Features: Unlimited storage, 99.9% uptime guarantee, 24/7 support\n",
    "    - Released: 2015, latest version 4.2 (2023)\n",
    "    \n",
    "    DataInsight: Enterprise data analytics solution\n",
    "    - Price: $499/month per 10 users\n",
    "    - Features: Real-time analytics, custom dashboards, ML-powered predictions\n",
    "    - Released: 2018, latest version 2.5 (2023)\n",
    "    \n",
    "    AI Assistant: Conversational AI platform for businesses\n",
    "    - Price: $199/month base + $10 per 1000 queries\n",
    "    - Features: Natural language processing, integration with 100+ business tools\n",
    "    - Released: 2020, latest version 1.8 (2023)\n",
    "    \"\"\",\n",
    "    \n",
    "    \"customer_support\": \"\"\"\n",
    "    Support hours: 24/7 for Enterprise plans, 8am-8pm EST for other plans\n",
    "    Contact methods:\n",
    "    - Email: support@techcorp.example\n",
    "    - Phone: 1-800-TECH-123\n",
    "    - Live chat: Available on website\n",
    "    \n",
    "    Average response time: 2 hours for Standard, 30 minutes for Premium, 10 minutes for Enterprise\n",
    "    Refund policy: 30-day money-back guarantee for all products\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who founded TechCorp and when?\n",
      "Response: TechCorp was founded in 2010 by Jane Smith and John Doe.\n",
      "\n",
      "Query: What is DataInsight and how much does it cost?\n",
      "Response: DataInsight is an enterprise data analytics solution that offers real-time analytics, custom dashboards, and ML-powered predictions. The price is $499 per month for every 10 users.\n",
      "\n",
      "Query: How can I contact customer support?\n",
      "Response: You can contact customer support through the following methods:\n",
      "\n",
      "- Email: support@techcorp.example\n",
      "- Phone: 1-800-TECH-123\n",
      "- Live chat: Available on the website\n"
     ]
    }
   ],
   "source": [
    "def simple_retriever(query: str, knowledge_base: Dict[str, str]) -> List[str]:\n",
    "    \"\"\"A simple keyword-based retriever for demonstration purposes.\n",
    "    \n",
    "    In a real-world application, this would be replaced with a proper vector database\n",
    "    and embedding-based semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        knowledge_base: Dictionary of knowledge chunks\n",
    "        \n",
    "    Returns:\n",
    "        List of relevant knowledge chunks\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    results = []\n",
    "    \n",
    "    # Simple keyword matching\n",
    "    keywords = {\n",
    "        \"company_info\": [\"founder\", \"founded\", \"headquarters\", \"employees\", \"revenue\", \"ceo\", \"cto\", \"company\"],\n",
    "        \"product_info\": [\"product\", \"price\", \"features\", \"techcloud\", \"datainsight\", \"ai assistant\", \"cost\", \"version\"],\n",
    "        \"customer_support\": [\"support\", \"contact\", \"email\", \"phone\", \"chat\", \"hours\", \"response time\", \"refund\"]\n",
    "    }\n",
    "    \n",
    "    # Check for keyword matches\n",
    "    for category, words in keywords.items():\n",
    "        if any(word in query_lower for word in words):\n",
    "            results.append(knowledge_base[category])\n",
    "    \n",
    "    # If no specific matches, return all knowledge\n",
    "    if not results:\n",
    "        results = list(knowledge_base.values())\n",
    "        \n",
    "    return results\n",
    "\n",
    "def rag_agent(user_input: str, knowledge_base: Dict[str, str], model: str = \"openai/gpt-4o-mini-2024-07-18\") -> str:\n",
    "    \"\"\"A simple RAG agent that retrieves information and augments the prompt.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's query\n",
    "        knowledge_base: The knowledge base to retrieve from\n",
    "        model: The model to use\n",
    "        \n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    # Retrieve relevant information\n",
    "    retrieved_info = simple_retriever(user_input, knowledge_base)\n",
    "    \n",
    "    # Construct the augmented prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are a company information assistant for TechCorp. Answer the user's question \n",
    "    based only on the provided information. If the answer is not in the information provided,\n",
    "    say that you don't have that information, but don't make up an answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add retrieved information to the system prompt\n",
    "    system_prompt += \"\\n\\nInformation:\\n\" + \"\\n\\n\".join(retrieved_info)\n",
    "    \n",
    "    # Make the API call\n",
    "    response = call_openrouter(\n",
    "        prompt=user_input,\n",
    "        model=model,\n",
    "        system_prompt=system_prompt,\n",
    "        temperature=0.3,  # Lower temperature for more factual responses\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Extract and return the text response\n",
    "    if response.get(\"success\", False):\n",
    "        return extract_text_response(response)\n",
    "    else:\n",
    "        return f\"Error: {response.get('error', 'Unknown error')}\"\n",
    "\n",
    "# Test the RAG agent with some queries\n",
    "company_query = \"Who founded TechCorp and when?\"\n",
    "product_query = \"What is DataInsight and how much does it cost?\"\n",
    "support_query = \"How can I contact customer support?\"\n",
    "\n",
    "print(f\"Query: {company_query}\")\n",
    "print(f\"Response: {rag_agent(company_query, knowledge_base)}\\n\")\n",
    "\n",
    "print(f\"Query: {product_query}\")\n",
    "print(f\"Response: {rag_agent(product_query, knowledge_base)}\\n\")\n",
    "\n",
    "print(f\"Query: {support_query}\")\n",
    "print(f\"Response: {rag_agent(support_query, knowledge_base)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Planning-Focused vs. Action-Focused Architectures\n",
    "\n",
    "Now let's explore the distinction between architectures that emphasize planning versus those that focus on actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Planning-Focused Architectures (Plan-and-Execute)\n",
    "\n",
    "Planning-focused architectures follow a \"plan-and-execute\" pattern. They first create a comprehensive plan with defined steps, then execute each step to complete the task.\n",
    "\n",
    "**Advantages:**\n",
    "- More efficient for complex, multi-step tasks\n",
    "- Better overall task completion through explicit planning\n",
    "- Reduces the number of LLM calls for executing steps\n",
    "- Allows for human review of plans before execution\n",
    "\n",
    "**Limitations:**\n",
    "- Less adaptable to unexpected situations\n",
    "- Initial planning step may miss important details\n",
    "- Plan quality heavily dependent on initial prompt quality\n",
    "- May struggle with tasks that require dynamic adjustment\n",
    "\n",
    "Let's implement a simple planning-focused agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Analyze the pros and cons of remote work for both employees and employers\n",
      "\n",
      "Generated Plan:\n",
      "1. **Define the Scope of Analysis**  \n",
      "   - Identify the key aspects of remote work to be analyzed for both employees and employers. This may include productivity, work-life balance, communication, cost savings, and employee satisfaction.\n",
      "\n",
      "2. **Conduct Literature Review**  \n",
      "   - Research existing studies, articles, and reports on remote work. Focus on both qualitative and quantitative data that highlight the pros and cons for employees and employers. Take notes on relevant findings.\n",
      "\n",
      "3. **Create a Pros and Cons Framework**  \n",
      "   - Develop a structured framework to categorize the pros and cons for both employees and employers. This could be a simple table with four quadrants: Employee Pros, Employee Cons, Employer Pros, and Employer Cons.\n",
      "\n",
      "4. **Gather Employee Perspectives**  \n",
      "   - Design and distribute a survey or conduct interviews with employees who have experience with remote work. Ask specific questions about their experiences, benefits, challenges, and overall satisfaction. Compile the responses.\n",
      "\n",
      "5. **Gather Employer Perspectives**  \n",
      "   - Similarly, design and distribute a survey or conduct interviews with employers or managers. Focus on their views regarding productivity, team dynamics, cost implications, and any challenges faced with remote work. Compile the responses.\n",
      "\n",
      "6. **Analyze Data and Identify Trends**  \n",
      "   - Review the collected data from both employees and employers. Identify common themes, trends, and significant differences in perspectives. Highlight key points that stand out in the analysis.\n",
      "\n",
      "7. **Draft the Final Analysis Report**  \n",
      "   - Write a comprehensive report summarizing the findings. Include sections for the pros and cons for both employees and employers, supported by data and quotes from the surveys/interviews. Ensure the report is clear, concise, and well-organized for easy understanding.\n",
      "\n",
      "Execution Results:\n",
      "\n",
      "Step 1 Execution:\n",
      "**Execution of Step 1: Define the Scope of Analysis**\n",
      "\n",
      "1. **Identify Key Aspects of Remote Work**: I will outline the key factors to analyze the pros and cons of remote work for both employees and emp...\n",
      "\n",
      "Step 2 Execution:\n",
      "To execute the step of conducting a literature review on the pros and cons of remote work for both employees and employers, I will follow these detailed steps:\n",
      "\n",
      "### 1. Identify Relevant Databases and ...\n",
      "\n",
      "Step 3 Execution:\n",
      "### Execution of Step 3: Create a Pros and Cons Framework\n",
      "\n",
      "#### Step 1: Outline the Framework Structure\n",
      "\n",
      "I will create a structured framework in the form of a four-quadrant table. The quadrants will b...\n",
      "\n",
      "Step 4 Execution:\n",
      "To execute the step of gathering employee perspectives on remote work, I will follow a detailed plan including the design of a survey, distribution methods, collection of responses, and compilation of...\n",
      "\n",
      "Step 5 Execution:\n",
      "### Execution of Step 5: Gather Employer Perspectives\n",
      "\n",
      "1. **Design the Survey for Employers**  \n",
      "   - I will create a survey consisting of specific questions that aim to gather insights into employer p...\n",
      "\n",
      "Step 6 Execution:\n",
      "To execute the step of analyzing data and identifying trends based on the perspectives gathered from employees and employers regarding remote work, I will proceed with the following detailed actions:\n",
      "...\n",
      "\n",
      "Step 7 Execution:\n",
      "**Draft the Final Analysis Report**\n",
      "\n",
      "---\n",
      "\n",
      "### Title: Remote Work: A Comprehensive Analysis of Pros and Cons for Employees and Employers\n",
      "\n",
      "**1. Introduction**\n",
      "\n",
      "The COVID-19 pandemic has accelerated the ...\n",
      "\n",
      "Final Summary:\n",
      "### Summary of Remote Work Analysis\n",
      "\n",
      "This analysis explored the pros and cons of remote work for both employees and employers, drawing from literature reviews and surveys conducted with 200 employees and 100 employers.\n",
      "\n",
      "#### Key Findings:\n",
      "\n",
      "**For Employees:**\n",
      "\n",
      "- **Pros:**\n",
      "  - **Flexibility:** 78% of employees valued the ability to manage their own schedules.\n",
      "  - **Work-Life Balance:** 65% reported improvements in work-life balance due to reduced commuting and increased personal time.\n",
      "  - **Productivity:** Many employees (approximately 70%) felt more productive at home due to fewer distractions.\n",
      "\n",
      "- **Cons:**\n",
      "  - **Isolation:** 20% of employees experienced feelings of loneliness, impacting mental health.\n",
      "  - **Work-Life Boundaries:** Difficulty in separating work from personal life led to increased burnout for some.\n",
      "  - **Communication Challenges:** Miscommunication in virtual settings was noted as a significant issue.\n",
      "\n",
      "**For Employers:**\n",
      "\n",
      "- **Pros:**\n",
      "  - **Cost Savings:** Employers reported savings on office space and utilities, with 60% noting reduced operational costs.\n",
      "  - **Talent Acquisition:** Access to a global talent pool was highlighted as a major benefit.\n",
      "  - **Employee Retention:** Increased job satisfaction among remote workers contributed to lower turnover rates.\n",
      "\n",
      "- **Cons:**\n",
      "  - **Management Challenges:** 55% of employers found it difficult to monitor employee performance and maintain team cohesion.\n",
      "  - **Company Culture:** Concerns about diminishing company culture and employee engagement were prevalent.\n",
      "  - **Security Risks:** Increased responsibility for data security and employee well-being was noted as a challenge.\n",
      "\n",
      "### Conclusion\n",
      "The analysis reveals that while remote work offers significant benefits such as flexibility and cost savings, it also presents challenges, particularly regarding communication, team dynamics, and employee isolation. Both employees and employers recognize the need for strategies to address these challenges to maximize the advantages of remote work.\n"
     ]
    }
   ],
   "source": [
    "def planning_agent(user_input: str, model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Dict[str, Any]:\n",
    "    \"\"\"A planning-focused agent that creates a plan first, then executes it.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's task\n",
    "        model: The model to use\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with plan, execution results, and final output\n",
    "    \"\"\"\n",
    "    # Step 1: Generate a plan\n",
    "    planning_prompt = f\"\"\"Task: {user_input}\n",
    "    \n",
    "    Create a detailed step-by-step plan to accomplish this task. Each step should be clear and actionable.\n",
    "    Format the plan as a numbered list. Include 3-7 steps depending on the complexity of the task.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_system_prompt = \"\"\"\n",
    "    You are a planning AI that creates detailed, logical plans to accomplish tasks.\n",
    "    Break complex tasks into clear, actionable steps that can be followed sequentially.\n",
    "    Focus only on creating the plan, not executing it.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_response = call_openrouter(\n",
    "        prompt=planning_prompt,\n",
    "        model=model,\n",
    "        system_prompt=planning_system_prompt,\n",
    "        temperature=0.3,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    if not planning_response.get(\"success\", False):\n",
    "        return {\"error\": f\"Planning failed: {planning_response.get('error', 'Unknown error')}\"}\n",
    "    \n",
    "    plan = extract_text_response(planning_response)\n",
    "    \n",
    "    # Step 2: Execute each step in the plan\n",
    "    # For demonstration, we'll simulate execution by having the LLM explain how it would execute each step\n",
    "    execution_results = []\n",
    "    \n",
    "    # Split the plan into steps (assuming it's a numbered list)\n",
    "    steps = []\n",
    "    for line in plan.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line and (line[0].isdigit() or (len(line) > 2 and line[0:2] in ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.'])):\n",
    "            steps.append(line)\n",
    "    \n",
    "    # If we couldn't parse numbered steps, treat the whole plan as one step\n",
    "    if not steps:\n",
    "        steps = [plan]\n",
    "    \n",
    "    for i, step in enumerate(steps):\n",
    "        execution_prompt = f\"\"\"Task: {user_input}\n",
    "        \n",
    "        Overall plan:\n",
    "        {plan}\n",
    "        \n",
    "        Current step to execute: {step}\n",
    "        \n",
    "        Explain in detail how you would execute this specific step. Provide the actual execution,\n",
    "        not just a theoretical explanation. If research or information gathering is needed,\n",
    "        provide realistic results.\n",
    "        \"\"\"\n",
    "        \n",
    "        execution_system_prompt = \"\"\"\n",
    "        You are an execution AI that carries out specific steps in a plan.\n",
    "        Focus only on executing the current step. Be thorough and detailed.\n",
    "        Provide concrete results, not just explanations of how you would approach it.\n",
    "        \"\"\"\n",
    "        \n",
    "        execution_response = call_openrouter(\n",
    "            prompt=execution_prompt,\n",
    "            model=model,\n",
    "            system_prompt=execution_system_prompt,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        if not execution_response.get(\"success\", False):\n",
    "            execution_results.append(f\"Error executing step {i+1}: {execution_response.get('error', 'Unknown error')}\")\n",
    "        else:\n",
    "            execution_results.append(extract_text_response(execution_response))\n",
    "    \n",
    "    # Step 3: Generate a final summary\n",
    "    summary_prompt = f\"\"\"Task: {user_input}\n",
    "    \n",
    "    Plan:\n",
    "    {plan}\n",
    "    \n",
    "    Execution results:\n",
    "    {\"..\".join([f\"Step {i+1}: {result}\" for i, result in enumerate(execution_results)])}\n",
    "    \n",
    "    Please provide a concise summary of the completed task, highlighting key findings or outcomes.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_system_prompt = \"\"\"\n",
    "    You are a summarization AI that synthesizes results from a multi-step process.\n",
    "    Provide a clear, concise summary that highlights the most important points and outcomes.\n",
    "    Focus on answering the original task/question directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_response = call_openrouter(\n",
    "        prompt=summary_prompt,\n",
    "        model=model,\n",
    "        system_prompt=summary_system_prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    if not summary_response.get(\"success\", False):\n",
    "        final_summary = f\"Error generating summary: {summary_response.get('error', 'Unknown error')}\"\n",
    "    else:\n",
    "        final_summary = extract_text_response(summary_response)\n",
    "    \n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"execution_results\": execution_results,\n",
    "        \"summary\": final_summary\n",
    "    }\n",
    "\n",
    "# Test the planning agent with a complex task\n",
    "complex_task = \"Analyze the pros and cons of remote work for both employees and employers\"\n",
    "planning_result = planning_agent(complex_task)\n",
    "\n",
    "print(f\"Task: {complex_task}\\n\")\n",
    "print(\"Generated Plan:\")\n",
    "print(planning_result[\"plan\"])\n",
    "print(\"\\nExecution Results:\")\n",
    "for i, result in enumerate(planning_result[\"execution_results\"]):\n",
    "    print(f\"\\nStep {i+1} Execution:\")\n",
    "    print(result[:200] + \"...\" if len(result) > 200 else result)\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(planning_result[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Action-Focused Architectures (ReAct)\n",
    "\n",
    "ReAct (Reasoning+Acting) is an action-focused architecture that interleaves reasoning and action steps. It follows a \"think-act-observe\" loop, making decisions dynamically based on the current state.\n",
    "\n",
    "**Advantages:**\n",
    "- More adaptable to changing conditions\n",
    "- Better handling of unexpected situations\n",
    "- Can explore and gather information dynamically\n",
    "- Good for tasks with uncertain paths or requirements\n",
    "\n",
    "**Limitations:**\n",
    "- Higher latency due to multiple LLM calls\n",
    "- May lead to inefficient exploration\n",
    "- Risk of getting stuck in loops\n",
    "- More complex to implement and debug\n",
    "\n",
    "Let's implement a simple ReAct agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Analyze the pros and cons of remote work for both employees and employers\n",
      "\n",
      "ReAct Thinking Steps:\n",
      "\n",
      "Step 1:\n",
      "Thought: To provide a comprehensive analysis of the pros and cons of remote work for both employees and employers, I will brainstorm and categorize the benefits and drawbacks for both sides. \n",
      "\n",
      "Action:...\n",
      "\n",
      "Tool Usage History:\n",
      "\n",
      "Final Answer:\n",
      "Remote work has distinct pros and cons for both employees and employers:\n",
      "\n",
      "### For Employees:\n",
      "**Pros:**\n",
      "- Flexibility in schedule and location.\n",
      "- Cost savings on commuting and work-related expenses.\n",
      "- Better work-life balance.\n",
      "- Increased productivity due to fewer distractions.\n",
      "\n",
      "**Cons:**\n",
      "- Feelings of isolation and disconnection from colleagues.\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "def react_agent(user_input: str, tools_dict: Dict[str, callable], model: str = \"openai/gpt-4o-mini-2024-07-18\", max_steps: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"A ReAct agent that follows the Reasoning+Acting pattern.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's task\n",
    "        tools_dict: Dictionary mapping tool names to functions\n",
    "        model: The model to use\n",
    "        max_steps: Maximum number of iterations\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with thinking steps, action history, and final answer\n",
    "    \"\"\"\n",
    "    # Convert tools to the format expected by the LLM\n",
    "    tools_spec = []\n",
    "    for tool_name, tool_fn in tools_dict.items():\n",
    "        # Get parameter list from function signature\n",
    "        import inspect\n",
    "        signature = inspect.signature(tool_fn)\n",
    "        params = {}\n",
    "        required = []\n",
    "        \n",
    "        for param_name, param in signature.parameters.items():\n",
    "            params[param_name] = {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": f\"The {param_name} parameter for {tool_name}\"\n",
    "            }\n",
    "            if param.default == inspect.Parameter.empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        tools_spec.append({\n",
    "            \"name\": tool_name,\n",
    "            \"description\": tool_fn.__doc__ or f\"The {tool_name} tool\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": params,\n",
    "                \"required\": required\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Initialize the conversation\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a problem-solving AI that follows the ReAct (Reasoning + Acting) framework.\n",
    "            For each step, you'll think about what needs to be done, choose an action, and then observe the result.\n",
    "            \n",
    "            Follow this format for each step:\n",
    "            Thought: <your reasoning about what to do next>\n",
    "            Action: <tool name to use>\n",
    "            \n",
    "            After seeing the observation, continue with your next thought.\n",
    "            When you have enough information to provide a final answer, use:\n",
    "            Thought: I now know the final answer\n",
    "            Final Answer: <your detailed answer to the original question>\n",
    "            \n",
    "            Always start with a Thought.\"\"\"}\n",
    "    ]\n",
    "    \n",
    "    # Add the user's task\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Initialize tracking\n",
    "    thinking_steps = []\n",
    "    action_history = []\n",
    "    final_answer = \"\"\n",
    "    \n",
    "    # ReAct loop\n",
    "    for step in range(max_steps):\n",
    "        # Get the next thought and action from the LLM\n",
    "        response = call_openrouter(\n",
    "            prompt=conversation_history,\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "            functions=tools_spec\n",
    "        )\n",
    "        \n",
    "        if not response.get(\"success\", False):\n",
    "            return {\"error\": f\"Error in step {step+1}: {response.get('error', 'Unknown error')}\"}\n",
    "        \n",
    "        # Get the assistant's response\n",
    "        assistant_response = extract_text_response(response)\n",
    "        thinking_steps.append(assistant_response)\n",
    "        \n",
    "        # Check if we've reached a final answer\n",
    "        if \"Final Answer:\" in assistant_response:\n",
    "            # Extract the final answer\n",
    "            final_answer = assistant_response.split(\"Final Answer:\")[1].strip()\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            break\n",
    "        \n",
    "        # Check for function calls\n",
    "        function_call = extract_function_call(response)\n",
    "        \n",
    "        if function_call.get(\"success\", False):\n",
    "            # Execute the function call\n",
    "            function_name = function_call.get(\"function_name\")\n",
    "            arguments = function_call.get(\"arguments\", {})\n",
    "            tool_id = function_call.get(\"tool_id\", \"call_\" + str(uuid.uuid4()))\n",
    "            \n",
    "            if function_name in tools_dict:\n",
    "                try:\n",
    "                    tool_result = tools_dict[function_name](**arguments)\n",
    "                    action_history.append({\"tool\": function_name, \"args\": arguments, \"result\": tool_result})\n",
    "                except Exception as e:\n",
    "                    tool_result = f\"Error executing {function_name}: {str(e)}\"\n",
    "                    action_history.append({\"tool\": function_name, \"args\": arguments, \"error\": str(e)})\n",
    "            else:\n",
    "                tool_result = f\"Error: Unknown tool '{function_name}'\"\n",
    "                action_history.append({\"tool\": function_name, \"args\": arguments, \"error\": \"Unknown tool\"})\n",
    "            \n",
    "            # Add the tool call and result to conversation using the new format\n",
    "            conversation_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_response,\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tool_id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": function_name,\n",
    "                            \"arguments\": json.dumps(arguments)\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_id,\n",
    "                \"content\": str(tool_result)\n",
    "            })\n",
    "        else:\n",
    "            # No function call, just thinking\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            # Add a prompt to nudge the agent to continue with the ReAct pattern\n",
    "            conversation_history.append({\"role\": \"user\", \"content\": \"Continue with your next thought and action.\"})\n",
    "    \n",
    "    # Check if we reached max steps without a final answer\n",
    "    if not final_answer:\n",
    "        # Ask for a final answer\n",
    "        final_prompt = \"You've reached the maximum number of steps. Please provide your final answer now based on what you've learned.\"\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": final_prompt})\n",
    "        \n",
    "        final_response = call_openrouter(\n",
    "            prompt=conversation_history,\n",
    "            model=model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        if final_response.get(\"success\", False):\n",
    "            final_answer = extract_text_response(final_response)\n",
    "        else:\n",
    "            final_answer = f\"Error getting final answer: {final_response.get('error', 'Unknown error')}\"\n",
    "    \n",
    "    return {\n",
    "        \"thinking_steps\": thinking_steps,\n",
    "        \"action_history\": action_history,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n",
    "\n",
    "# Define additional tools for the ReAct agent\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simulated web search tool.\"\"\"\n",
    "    # In a real application, this would call a search API\n",
    "    search_results = {\n",
    "        \"remote work\": \"Recent studies show 70% of companies plan to adopt hybrid work models post-pandemic. Benefits include reduced office costs and wider talent pools. Challenges include team cohesion and maintaining company culture.\",\n",
    "        \"employee satisfaction\": \"84% of remote workers report increased job satisfaction according to a 2023 survey. Key factors include better work-life balance and eliminated commute time.\",\n",
    "        \"productivity\": \"Studies on remote work productivity show mixed results. Some report up to 13% productivity gains, while others note 10-15% decreases, particularly for collaborative tasks.\",\n",
    "        \"employer benefits\": \"Employers report 22% reduction in turnover, 30% reduction in real estate costs, and access to 70% larger talent pools with remote work policies.\",\n",
    "        \"challenges\": \"Top challenges of remote work include: communication difficulties (63%), isolation/loneliness (59%), difficulty separating work/home life (47%), and managing remote teams (44%).\"\n",
    "    }\n",
    "    \n",
    "    # Find the closest matching query\n",
    "    query_lower = query.lower()\n",
    "    for key, value in search_results.items():\n",
    "        if key in query_lower:\n",
    "            return f\"Search results for '{query}': {value}\"\n",
    "    \n",
    "    return f\"No specific results found for '{query}'. Try a more specific search term.\"\n",
    "\n",
    "def get_statistics(topic: str) -> str:\n",
    "    \"\"\"Simulated statistics lookup tool.\"\"\"\n",
    "    stats = {\n",
    "        \"remote work\": \"\"\"\n",
    "        - 16% of companies globally are fully remote (Owl Labs, 2023)\n",
    "        - 98% of workers want to work remotely at least some of the time (Buffer, 2023)\n",
    "        - 77% of remote workers report higher productivity (Stanford, 2022)\n",
    "        - 55% of businesses globally offer some capacity for remote work (Gartner, 2023)\n",
    "        \"\"\",\n",
    "        \n",
    "        \"employee satisfaction\": \"\"\"\n",
    "        - Remote workers are 22% happier than workers in an office setting (Tracking Happiness, 2023)\n",
    "        - 74% of workers say that having remote options would make them less likely to leave a company (Owl Labs, 2023)\n",
    "        - Remote workers save 40-60 minutes per day without commuting (Upwork, 2022)\n",
    "        \"\"\",\n",
    "        \n",
    "        \"employer benefits\": \"\"\"\n",
    "        - Companies save an average of $11,000 per year per employee who works remotely half-time (Global Workplace Analytics, 2023)\n",
    "        - Remote companies see 25% less turnover than companies without remote options (Owl Labs, 2023)\n",
    "        - 63% of high-growth companies use a \"productivity anywhere\" workforce model (Accenture, 2022)\n",
    "        \"\"\",\n",
    "        \n",
    "        \"challenges\": \"\"\"\n",
    "        - 60% of remote workers report feeling less connected to their teams (Buffer, 2023)\n",
    "        - 45% of remote workers report working more hours than they did in the office (Owl Labs, 2022)\n",
    "        - 32% of managers say they struggle with managing the performance of remote workers (Harvard Business Review, 2023)\n",
    "        - 27% of remote workers have experienced feelings of isolation or loneliness (Buffer, 2023)\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # Find the closest matching topic\n",
    "    topic_lower = topic.lower()\n",
    "    for key, value in stats.items():\n",
    "        if key in topic_lower:\n",
    "            return f\"Statistics on {topic}: {value}\"\n",
    "    \n",
    "    return f\"No statistics found for '{topic}'. Available topics: remote work, employee satisfaction, employer benefits, challenges.\"\n",
    "\n",
    "# Create a tools dictionary\n",
    "tools = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate\": calculate,\n",
    "    \"search_web\": search_web,\n",
    "    \"get_statistics\": get_statistics\n",
    "}\n",
    "\n",
    "# Test the ReAct agent\n",
    "react_task = \"Analyze the pros and cons of remote work for both employees and employers\"\n",
    "react_result = react_agent(react_task, tools)\n",
    "\n",
    "print(f\"Task: {react_task}\\n\")\n",
    "print(\"ReAct Thinking Steps:\")\n",
    "for i, step in enumerate(react_result[\"thinking_steps\"]):\n",
    "    print(f\"\\nStep {i+1}:\")\n",
    "    print(step[:200] + \"...\" if len(step) > 200 else step)\n",
    "\n",
    "print(\"\\nTool Usage History:\")\n",
    "for i, action in enumerate(react_result[\"action_history\"]):\n",
    "    print(f\"\\nAction {i+1}: Used {action['tool']} with args {action['args']}\")\n",
    "    if \"result\" in action:\n",
    "        print(f\"Result: {action['result'][:100]}...\" if len(action['result']) > 100 else f\"Result: {action['result']}\")\n",
    "    else:\n",
    "        print(f\"Error: {action['error']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(react_result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Approaches and When To Use Them\n",
    "\n",
    "In practice, many effective agent architectures combine elements from different patterns to leverage their respective strengths. Let's explore some hybrid approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Plan-Then-ReAct Hybrid\n",
    "\n",
    "This hybrid approach starts with a planning phase to create a high-level strategy, then uses ReAct for dynamic execution of each step. This combines the strategic overview of planning-focused approaches with the adaptability of action-focused ones.\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Complex tasks with uncertain subtasks\n",
    "- Tasks requiring both structure and flexibility\n",
    "- Information-gathering tasks with an overall goal\n",
    "- Research and analysis projects\n",
    "\n",
    "Let's implement a simple Plan-Then-ReAct hybrid agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Research the impact of artificial intelligence on healthcare, including benefits and challenges\n",
      "\n",
      "Generated Plan:\n",
      "1. **Define Research Objectives and Scope**  \n",
      "   - Identify specific areas of healthcare impacted by AI (e.g., diagnostics, treatment planning, patient management).\n",
      "   - Determine the key benefits and challenges to be explored (e.g., efficiency, accuracy, ethical concerns, data privacy).\n",
      "\n",
      "2. **Conduct Literature Review**  \n",
      "   - Gather existing research papers, articles, and case studies on AI applications in healthcare.\n",
      "   - Summarize findings on both the benefits and challenges of AI integration in healthcare settings.\n",
      "\n",
      "3. **Identify Key Stakeholders and Experts**  \n",
      "   - List relevant stakeholders in the healthcare and AI sectors (e.g., healthcare providers, technology developers, regulatory bodies).\n",
      "   - Plan outreach to experts for interviews or surveys to gain insights on real-world applications and challenges.\n",
      "\n",
      "4. **Analyze Collected Data**  \n",
      "   - Synthesize information from literature and expert insights to identify common themes and trends.\n",
      "   - Evaluate the impact of AI on healthcare outcomes, operational efficiency, and patient experience.\n",
      "\n",
      "5. **Develop Conclusions and Recommendations**  \n",
      "   - Formulate a comprehensive overview of the benefits and challenges of AI in healthcare based on the analysis.\n",
      "   - Propose actionable recommendations for stakeholders on how to maximize benefits while addressing challenges.\n",
      "\n",
      "Execution Summary:\n",
      "\n",
      "Step 1: 1. **Define Research Objectives and Scope**\n",
      "Result: Thought: I was unable to gather specific information through web searches due to limitations in the ...\n",
      "\n",
      "Step 2: 2. **Conduct Literature Review**\n",
      "Result: Thought: I need to consolidate the information I have gathered about the impact of artificial intell...\n",
      "\n",
      "Step 3: 3. **Identify Key Stakeholders and Experts**\n",
      "Result: Thought: I have been unable to retrieve specific data through web searches, but I can summarize the ...\n",
      "\n",
      "Step 4: 4. **Analyze Collected Data**\n",
      "Result: Thought: I now know the final answer based on the analysis of the various aspects of artificial inte...\n",
      "\n",
      "Step 5: 5. **Develop Conclusions and Recommendations**\n",
      "Result: Thought: I have gathered sufficient context about the impact of artificial intelligence in healthcar...\n",
      "\n",
      "Final Answer:\n",
      "The integration of artificial intelligence (AI) in healthcare is transforming the landscape of medical services, diagnostics, treatment planning, and patient management. This synthesis outlines the key benefits and challenges associated with AI in healthcare, based on a comprehensive review of existing literature, expert insights, and stakeholder perspectives.\n",
      "\n",
      "### Impact of AI on Healthcare\n",
      "\n",
      "AI technologies are making significant inroads into various domains of healthcare, including:\n",
      "\n",
      "1. **Diag...\n"
     ]
    }
   ],
   "source": [
    "def plan_then_react_agent(user_input: str, tools_dict: Dict[str, callable], model: str = \"openai/gpt-4o-mini-2024-07-18\") -> Dict[str, Any]:\n",
    "    \"\"\"A hybrid agent that first plans, then uses ReAct for execution.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's task\n",
    "        tools_dict: Dictionary mapping tool names to functions\n",
    "        model: The model to use\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with plan, execution history, and final answer\n",
    "    \"\"\"\n",
    "    # Step 1: Generate a plan\n",
    "    planning_prompt = f\"\"\"Task: {user_input}\n",
    "    \n",
    "    Create a high-level plan to accomplish this task. Each step should be clear and actionable.\n",
    "    Focus on what information needs to be gathered and what analyses need to be performed.\n",
    "    Format the plan as a numbered list with 3-5 main steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_system_prompt = \"\"\"\n",
    "    You are a planning AI that creates strategic plans to accomplish tasks.\n",
    "    Break complex tasks into high-level steps that guide the overall approach.\n",
    "    Focus on the overall strategy, not detailed execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    planning_response = call_openrouter(\n",
    "        prompt=planning_prompt,\n",
    "        model=model,\n",
    "        system_prompt=planning_system_prompt,\n",
    "        temperature=0.3,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    if not planning_response.get(\"success\", False):\n",
    "        return {\"error\": f\"Planning failed: {planning_response.get('error', 'Unknown error')}\"}\n",
    "    \n",
    "    plan = extract_text_response(planning_response)\n",
    "    \n",
    "    # Step 2: Execute each high-level step using ReAct\n",
    "    # Split the plan into steps (assuming it's a numbered list)\n",
    "    steps = []\n",
    "    for line in plan.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line and (line[0].isdigit() or (len(line) > 2 and line[0:2] in ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.'])):\n",
    "            steps.append(line)\n",
    "    \n",
    "    # If we couldn't parse numbered steps, treat the whole plan as one step\n",
    "    if not steps:\n",
    "        steps = [plan]\n",
    "    \n",
    "    step_executions = []\n",
    "    all_thinking_steps = []\n",
    "    all_action_history = []\n",
    "    \n",
    "    for i, step in enumerate(steps):\n",
    "        step_prompt = f\"\"\"\n",
    "        \n",
    "        Overall Task: {user_input}\n",
    "        \n",
    "        Overall Plan:\n",
    "        {plan}\n",
    "        \n",
    "        Current Step to Execute: {step}\n",
    "        \n",
    "        Execute this specific step using the available tools. Gather information, perform analysis,\n",
    "        and provide detailed results for this step.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use ReAct for this specific step\n",
    "        react_result = react_agent(step_prompt, tools_dict, model, max_steps=3)\n",
    "        \n",
    "        if \"error\" in react_result:\n",
    "            step_executions.append({\"step\": step, \"error\": react_result[\"error\"]})\n",
    "        else:\n",
    "            step_executions.append({\n",
    "                \"step\": step,\n",
    "                \"thinking\": react_result[\"thinking_steps\"],\n",
    "                \"actions\": react_result[\"action_history\"],\n",
    "                \"result\": react_result[\"final_answer\"]\n",
    "            })\n",
    "            all_thinking_steps.extend(react_result[\"thinking_steps\"])\n",
    "            all_action_history.extend(react_result[\"action_history\"])\n",
    "    \n",
    "    # Step 3: Generate a final summary\n",
    "    summary_prompt = f\"\"\"Task: {user_input}\n",
    "    \n",
    "    Plan:\n",
    "    {plan}\n",
    "    \n",
    "    Execution results:\n",
    "    {\"..\".join([f\"Step {i+1}: {exec_result.get('result', exec_result.get('error', 'Unknown error'))}\" for i, exec_result in enumerate(step_executions)])}\n",
    "    \n",
    "    Please provide a comprehensive answer to the original task, synthesizing all the information collected.\n",
    "    Be detailed and thorough.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_system_prompt = \"\"\"\n",
    "    You are a synthesis AI that consolidates information from multiple sources.\n",
    "    Provide a comprehensive, cohesive answer that addresses all aspects of the original task.\n",
    "    Include specific details and insights from the execution results.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_response = call_openrouter(\n",
    "        prompt=summary_prompt,\n",
    "        model=model,\n",
    "        system_prompt=summary_system_prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    \n",
    "    if not summary_response.get(\"success\", False):\n",
    "        final_summary = f\"Error generating summary: {summary_response.get('error', 'Unknown error')}\"\n",
    "    else:\n",
    "        final_summary = extract_text_response(summary_response)\n",
    "    \n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"step_executions\": step_executions,\n",
    "        \"all_thinking_steps\": all_thinking_steps,\n",
    "        \"all_action_history\": all_action_history,\n",
    "        \"final_answer\": final_summary\n",
    "    }\n",
    "\n",
    "# Test the hybrid agent\n",
    "hybrid_task = \"Research the impact of artificial intelligence on healthcare, including benefits and challenges\"\n",
    "hybrid_result = plan_then_react_agent(hybrid_task, tools)\n",
    "\n",
    "print(f\"Task: {hybrid_task}\\n\")\n",
    "print(\"Generated Plan:\")\n",
    "print(hybrid_result[\"plan\"])\n",
    "\n",
    "print(\"\\nExecution Summary:\")\n",
    "for i, step_exec in enumerate(hybrid_result[\"step_executions\"]):\n",
    "    print(f\"\\nStep {i+1}: {step_exec['step']}\")\n",
    "    if \"result\" in step_exec:\n",
    "        print(f\"Result: {step_exec['result'][:100]}...\" if len(step_exec['result']) > 100 else f\"Result: {step_exec['result']}\")\n",
    "    else:\n",
    "        print(f\"Error: {step_exec['error']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(hybrid_result[\"final_answer\"][:500] + \"...\" if len(hybrid_result[\"final_answer\"]) > 500 else hybrid_result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 When to Use Different Architectures\n",
    "\n",
    "Choosing the right agent architecture depends on the specific task requirements and constraints. Here's a guide for when to use each approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-Turn Agents\n",
    "- **Best for**: Simple queries, factual questions, straightforward tasks\n",
    "- **When to use**: Low latency is critical, costs need to be minimized, user queries are typically simple\n",
    "- **Example use cases**: FAQ answering, simple content generation, style transfer, summarization\n",
    "\n",
    "#### Multi-Turn Agents\n",
    "- **Best for**: Conversations, iterative tasks, tasks requiring clarification\n",
    "- **When to use**: User interaction is important, task clarity emerges through dialogue\n",
    "- **Example use cases**: Customer support, tutoring, interviewing, coaching\n",
    "\n",
    "#### Tool-Based Agents\n",
    "- **Best for**: Tasks requiring external actions or data retrieval\n",
    "- **When to use**: When LLM knowledge is insufficient, real-world actions are needed\n",
    "- **Example use cases**: Booking systems, data analysis, workflow automation, personal assistants\n",
    "\n",
    "#### RAG-Based Agents\n",
    "- **Best for**: Knowledge-intensive tasks with domain-specific information\n",
    "- **When to use**: When information is available but not in the LLM's training data\n",
    "- **Example use cases**: Legal assistance, medical information, technical support, research\n",
    "\n",
    "#### Planning-Focused Agents\n",
    "- **Best for**: Complex tasks with clear steps, predictable workflows\n",
    "- **When to use**: When efficiency matters, steps are known in advance, human oversight is available\n",
    "- **Example use cases**: Project planning, document writing, analysis reports, code generation\n",
    "\n",
    "#### Action-Focused (ReAct) Agents\n",
    "- **Best for**: Exploratory tasks, unpredictable workflows, information gathering\n",
    "- **When to use**: When adaptability matters more than efficiency, dynamic exploration is needed\n",
    "- **Example use cases**: Research, troubleshooting, creative problem-solving, open-ended exploration\n",
    "\n",
    "#### Hybrid Agents\n",
    "- **Best for**: Complex tasks with both structured and unpredictable elements\n",
    "- **When to use**: When neither planning-only nor react-only approaches are sufficient\n",
    "- **Example use cases**: Comprehensive research projects, product development, strategic planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Best Practices\n",
    "\n",
    "In this notebook, we've explored various agent architecture patterns for building LLM-based systems. Each pattern has its own strengths, limitations, and ideal use cases.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Match architecture to task requirements**: Consider the nature of the task, expected user interactions, and system constraints when choosing an architecture.\n",
    "\n",
    "2. **Start simple and scale up**: Begin with the simplest architecture that meets your needs, then add complexity only when necessary.\n",
    "\n",
    "3. **Consider hybrid approaches**: Many real-world applications benefit from combining elements of different architectural patterns.\n",
    "\n",
    "4. **Evaluate empirically**: Test different architectures with real users and measure performance on key metrics.\n",
    "\n",
    "5. **Balance cost and performance**: More complex architectures often require more LLM calls, increasing latency and cost.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Clear system prompts**: Regardless of architecture, provide clear, detailed instructions to the LLM.\n",
    "\n",
    "2. **Error handling**: Implement robust error handling for all components, especially for tool calls.\n",
    "\n",
    "3. **User feedback**: Create mechanisms for users to provide feedback when agent responses miss the mark.\n",
    "\n",
    "4. **Continuous improvement**: Collect and analyze interaction logs to identify failure modes and improvement opportunities.\n",
    "\n",
    "5. **Responsible design**: Implement safeguards against misuse, bias, and harmful outputs.\n",
    "\n",
    "6. **Transparency**: Make the agent's capabilities and limitations clear to users to set appropriate expectations.\n",
    "\n",
    "By understanding and applying these different architectural patterns, you can build more effective, reliable, and user-friendly LLM-based agents for a wide range of applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
